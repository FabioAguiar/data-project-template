{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b360890a",
   "metadata": {},
   "source": [
    "# Prepara√ß√£o de Dados (N1)\n",
    "\n",
    "## üóÇÔ∏è [ Projeto ]\n",
    "\n",
    "**Nome do Projeto:** [nome do projeto]  \n",
    "**Dataset:** [Nome do dataset ou fonte de dados]  \n",
    "**Objetivo Geral:** [Breve Explica√ß√£o do prop√≥sito ‚Äî ex.: ‚ÄúAnalisar o comportamento de churn e identificar fatores de reten√ß√£o de clientes.‚Äù]  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã Descri√ß√£o Geral do Tratamento\n",
    "\n",
    "Nesta etapa ser√£o realizados os principais **processos de limpeza, transforma√ß√£o e padroniza√ß√£o dos dados**.  \n",
    "O foco √© garantir que o dataset esteja **consistente, estruturado e pronto para an√°lises posteriores**.\n",
    "\n",
    "**Tarefas previstas:**  \n",
    "- Leitura e diagn√≥stico inicial do dataset.  \n",
    "- Tratamento de valores nulos, duplicados e outliers.  \n",
    "- Convers√£o de tipos e padroniza√ß√£o de nomes de colunas.  \n",
    "- Codifica√ß√£o de vari√°veis categ√≥ricas e normaliza√ß√£o de num√©ricas (quando necess√°rio).  \n",
    "- Gera√ß√£o de artefatos intermedi√°rios e relat√≥rio de qualidade dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91f747",
   "metadata": {},
   "source": [
    "## üîß Configura√ß√£o do Projeto (Bootstrap)\n",
    "\n",
    "Esta etapa realiza o **bootstrap do ambiente de execu√ß√£o**, preparando o notebook para funcionar em qualquer m√°quina ‚Äî garantindo **reprodutibilidade**, **organiza√ß√£o** e **autonomia**.  \n",
    "Todas as depend√™ncias, caminhos e configura√ß√µes s√£o ajustadas automaticamente, sem necessidade de modifica√ß√µes manuais.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Etapas realizadas\n",
    "\n",
    "#### üß≠ 1. Localiza√ß√£o da raiz do projeto  \n",
    "- Busca o arquivo `config/defaults.json` subindo diret√≥rios at√© encontr√°-lo.  \n",
    "- Define `PROJECT_ROOT` como ponto de refer√™ncia global para todos os caminhos do projeto.\n",
    "\n",
    "#### üß© 2. Valida√ß√£o da estrutura `utils/`  \n",
    "- Verifica se existem a pasta `utils/` e o arquivo `__init__.py` (criado automaticamente, se ausente).  \n",
    "- Garante que o pacote seja reconhecido pelo Python, permitindo importar `utils.utils_data` sem erros.\n",
    "\n",
    "#### üß± 3. Registro no `sys.path`  \n",
    "- Adiciona o diret√≥rio raiz (`PROJECT_ROOT`) ao `sys.path`, habilitando o uso de m√≥dulos internos em qualquer ambiente.  \n",
    "- Exibe o caminho detectado e o status do registro.\n",
    "\n",
    "#### ‚ôªÔ∏è 4. Importa√ß√£o e recarregamento das utilidades  \n",
    "- Importa o m√≥dulo `utils.utils_data` e o recarrega via `importlib.reload`.  \n",
    "- Essa abordagem assegura que o notebook use **sempre a vers√£o mais recente** do arquivo durante o desenvolvimento iterativo.\n",
    "\n",
    "#### üßæ 5. Inicializa√ß√£o do sistema de logs  \n",
    "- Cria um log unificado em `reports/data_preparation.log`.  \n",
    "- Cada etapa importante (carregamento, limpeza, exporta√ß√£o etc.) √© registrada tanto no **console** quanto em **arquivo**, facilitando a rastreabilidade do processo.\n",
    "\n",
    "#### ‚öôÔ∏è 6. Carregamento das configura√ß√µes globais  \n",
    "- L√™ os par√¢metros de `config/defaults.json` e, se existir, aplica substitui√ß√µes de `config/local.json`.  \n",
    "- Esses par√¢metros controlam o comportamento de cada etapa (tratamento de nulos, tipagem, outliers, encoding etc.).\n",
    "\n",
    "#### üìÇ 7. Resolu√ß√£o de diret√≥rios e arquivos padr√£o  \n",
    "- Garante a exist√™ncia das pastas principais:  \n",
    "  `data/raw`, `data/interim`, `data/processed`, `reports`, `artifacts`, `prints`, `dashboards`.  \n",
    "- Define os arquivos de sa√≠da padr√£o (interim e processed), mantendo compatibilidade entre notebooks.\n",
    "\n",
    "#### üîÑ 8. Ambiente reprodut√≠vel e consistente  \n",
    "- Define a semente aleat√≥ria (`RANDOM_SEED = 42`) para resultados reprodut√≠veis.  \n",
    "- Ajusta as op√ß√µes de exibi√ß√£o do pandas (`max_columns` e `display.width`) para uma visualiza√ß√£o mais confort√°vel.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Resultado esperado\n",
    "\n",
    "Ao final desta c√©lula:\n",
    "\n",
    "- O projeto √© **reconhecido automaticamente**, independentemente do ambiente de execu√ß√£o.  \n",
    "- O m√≥dulo `utils_data.py` √© importado com todas as fun√ß√µes utilit√°rias dispon√≠veis.  \n",
    "- As pastas e arquivos padr√£o s√£o criados e configurados.  \n",
    "- O log central come√ßa a registrar todas as a√ß√µes executadas nas pr√≥ximas etapas.  \n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:** Este design modular permite que o mesmo notebook seja executado em qualquer reposit√≥rio que siga a estrutura do template, sem ajustes manuais de caminho ou imports.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1233a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] sys.path ok. utils: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\n",
      "2025-11-02 11:57:13,188 | INFO | Bootstrap conclu√≠do.\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:13,190 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] sys.path ok. utils: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\n",
      "2025-11-02 11:57:13,191 | INFO | sys.path ok. utils: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\n",
      "2025-11-02 11:57:13,193 | INFO | Config carregada e paths resolvidos.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Bootstrap do projeto ‚Äî encontra a raiz, injeta no sys.path e garante utils/__init__.py\n",
    "\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import random, numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "def _find_up(relative_path: str, start: Path | None = None) -> Path | None:\n",
    "    start = start or Path.cwd()\n",
    "    rel = Path(relative_path)\n",
    "    for base in (start, *start.parents):\n",
    "        cand = base / rel\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "    return None\n",
    "\n",
    "# 1) Descobrir a raiz a partir do config/defaults.json\n",
    "_cfg = _find_up(\"config/defaults.json\")\n",
    "if _cfg is None:\n",
    "    raise FileNotFoundError(\"config/defaults.json n√£o encontrado. Confirme a estrutura do projeto.\")\n",
    "PROJECT_ROOT = _cfg.parent.parent.resolve()\n",
    "print(f\"[INFO] PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "\n",
    "# 2) Garantir pasta utils/ e __init__.py\n",
    "UTILS_DIR = PROJECT_ROOT / \"utils\"\n",
    "INIT_FILE = UTILS_DIR / \"__init__.py\"\n",
    "if not UTILS_DIR.exists():\n",
    "    raise ModuleNotFoundError(f\"Pasta n√£o encontrada: {UTILS_DIR} (crie 'utils' na raiz).\")\n",
    "if not INIT_FILE.exists():\n",
    "    INIT_FILE.write_text(\"\", encoding=\"utf-8\")\n",
    "    print(f\"[INFO] Criado: {INIT_FILE}\")\n",
    "\n",
    "# 3) Injetar a raiz no sys.path\n",
    "root_str = str(PROJECT_ROOT)\n",
    "if root_str not in sys.path:\n",
    "    sys.path.insert(0, root_str)\n",
    "print(f\"[INFO] sys.path ok. utils: {UTILS_DIR}\")\n",
    "\n",
    "# 4) Importar utils.utils_data\n",
    "import utils.utils_data as ud\n",
    "importlib.reload(ud)  # garante vers√£o mais recente ao iterar no notebook\n",
    "\n",
    "# 5) Configurar logging base do notebook\n",
    "LOG_FILE = (PROJECT_ROOT / \"reports\" / \"data_preparation.log\")\n",
    "LOG_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler(LOG_FILE, encoding=\"utf-8\")],\n",
    "    force=True,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Bootstrap conclu√≠do.\")\n",
    "\n",
    "# 6) Carregar configura√ß√µes\n",
    "config = ud.load_config(PROJECT_ROOT / \"config\" / \"defaults.json\",\n",
    "                        PROJECT_ROOT / \"config\" / \"local.json\")\n",
    "\n",
    "# >>> CORRE√á√ÉO AQUI <<<\n",
    "# paths = ud.resolve_n1_paths(config, PROJECT_ROOT)   # ERRADO\n",
    "paths = ud.resolve_n1_paths(PROJECT_ROOT)             # CERTO (ou simplesmente ud.resolve_n1_paths())\n",
    "\n",
    "# 7) Seed e display (substitui ud.set_random_seed / ud.set_display)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "logger.info(\"Config carregada e paths resolvidos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3b97c-5cc9-41d4-b535-b806e2df2e0b",
   "metadata": {},
   "source": [
    "## üîß Configura√ß√£o de Fontes\n",
    "\n",
    "Nesta etapa s√£o definidos os **arquivos de origem** que servir√£o de base para o projeto.  \n",
    "Aqui voc√™ informa **quais datasets ser√£o utilizados**, **em qual formato** est√£o (CSV ou Parquet) e, se houver mais de uma fonte, **como elas se relacionam**.\n",
    "\n",
    "---\n",
    "\n",
    "### üóÇÔ∏è 1. Explora√ß√£o das fontes dispon√≠veis\n",
    "\n",
    "Antes de configurar o dicion√°rio `SOURCES`, √© poss√≠vel listar os arquivos presentes no diret√≥rio `data/raw/`:\n",
    "\n",
    "```python\n",
    "from utils.utils_data import suggest_source_path, path_of\n",
    "\n",
    "RAW_DIR = paths.raw_dir\n",
    "suggest_source_path(RAW_DIR, pattern=\"*.csv\")\n",
    "```\n",
    "\n",
    "Esse comando exibe uma tabela com os arquivos encontrados e gera uma **sugest√£o autom√°tica de caminho** para copiar e colar no `SOURCES`.  \n",
    "Basta arrastar o arquivo para a pasta `data/raw/` e executar o bloco ‚Äî o nome aparecer√° pronto para uso.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 2. Defini√ß√£o das fontes de dados (`SOURCES`)\n",
    "\n",
    "- Cada entrada do dicion√°rio `SOURCES` representa uma tabela nomeada.  \n",
    "- A chave (ex.: `\"main\"`, `\"dim_customers\"`) identifica a tabela no projeto.  \n",
    "- Cada item cont√©m:\n",
    "  - `path`: caminho do arquivo dentro de `data/raw/`.  \n",
    "  - `format`: formato opcional (`\"csv\"` ou `\"parquet\"`). Se omitido, o formato √© detectado automaticamente.  \n",
    "  - `read_opts`: par√¢metros de leitura personalizados (`encoding`, `sep`, `low_memory`, etc.).\n",
    "\n",
    "Exemplo de estrutura:\n",
    "```python\n",
    "SOURCES = {\n",
    "    \"main\": {\n",
    "        \"path\": RAW_DIR / \"dataset.csv\",\n",
    "        \"read_opts\": {\"encoding\": \"utf-8\", \"sep\": \",\", \"low_memory\": False}\n",
    "    },\n",
    "    # Exemplo de segunda fonte em CSV:\n",
    "    # \"dim_customers\": {\n",
    "    #     \"path\": RAW_DIR / \"exemplo.csv\",\n",
    "    #     \"format\": \"csv\"\n",
    "    # }\n",
    "    # Exemplo de fonte em Parquet:\n",
    "    # \"dim_customers\": {\n",
    "    #     \"path\": RAW_DIR / \"customers.parquet\",\n",
    "    #     \"format\": \"parquet\"\n",
    "    # }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîó 3. Configura√ß√£o opcional de jun√ß√µes (`MERGE_STEPS`)\n",
    "\n",
    "O DataFrame principal √© o definido em `MAIN_SOURCE` (geralmente `\"main\"`).  \n",
    "Se existirem outras fontes, voc√™ pode configur√°-las em `MERGE_STEPS` para realizar merges autom√°ticos:\n",
    "\n",
    "```python\n",
    "MAIN_SOURCE = \"main\"\n",
    "MERGE_STEPS = [\n",
    "    # (\"dim_customers\", \"left\", \"customer_id\", \"id\"),\n",
    "]\n",
    "```\n",
    "\n",
    "Cada item define:\n",
    "- o nome da tabela secund√°ria (`right_name`),\n",
    "- o tipo de jun√ß√£o (`how`),\n",
    "- e as chaves de correspond√™ncia (`left_on`, `right_on`).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 4. Valida√ß√£o e feedback autom√°tico\n",
    "\n",
    "Ap√≥s definir as fontes, o bloco final realiza uma checagem simples:\n",
    "\n",
    "- Confirma se o arquivo principal existe.  \n",
    "- Detecta automaticamente o formato (`CSV` ou `Parquet`).  \n",
    "- Exibe mensagens de status amig√°veis:\n",
    "\n",
    "```\n",
    "‚úÖ Fontes configuradas com sucesso.\n",
    "‚Üí Fonte principal: 'main'  | Arquivo: dataset.csv  | Formato detectado: CSV\n",
    "‚Üí Nenhum merge configurado (usando apenas a fonte principal).\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> üí° Resumo\n",
    ">\n",
    ">Essa abordagem torna a **configura√ß√£o de fontes interativa, leve e flex√≠vel**:\n",
    ">- Basta colocar novos arquivos em `data/raw/` e usar `suggest_source_path()` para gerar o caminho.  \n",
    ">- N√£o h√° necessidade de alterar outros blocos do notebook ‚Äî apenas o `SOURCES` e, se necess√°rio, os merges.  \n",
    ">- Ideal para projetos explorat√≥rios e notebooks reutiliz√°veis em diferentes datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681bf24a-8f54-42eb-8e41-3854c616d924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [suggest_source_path] 1 arquivo(s) encontrados; exibindo 1.\n",
      "2025-11-02 11:57:14,792 | INFO | [suggest_source_path] 1 arquivo(s) encontrados; exibindo 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\fabio\\Projetos DEV\\data projects\\data...</td>\n",
       "      <td>dataset.csv</td>\n",
       "      <td>977501</td>\n",
       "      <td>2019-09-27T19:30:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path         name  size_bytes  \\\n",
       "0  C:\\Users\\fabio\\Projetos DEV\\data projects\\data...  dataset.csv      977501   \n",
       "\n",
       "              modified  \n",
       "0  2019-09-27T19:30:08  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, importlib\n",
    "sys.path.insert(0, r\"C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\")\n",
    "import importlib, utils_data as ud\n",
    "importlib.reload(ud)\n",
    "\n",
    "RAW_DIR = paths.raw_dir\n",
    "ud.suggest_source_path(RAW_DIR, pattern=\"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58848935-7ea0-4afd-956c-c5181584c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fontes configuradas com sucesso.\n",
      "‚Üí Fonte principal: 'main'  | Arquivo: dataset.csv  | Formato detectado: CSV\n",
      "‚Üí Nenhum merge configurado (usando apenas a fonte principal).\n"
     ]
    }
   ],
   "source": [
    "# Obs: s√≥ alterar este bloco quando precisar mudar os arquivos ou as chaves de jun√ß√£o.\n",
    "\n",
    "SOURCES = {\n",
    "    # nome_da_tabela: {path, (opcional) format: 'csv'|'parquet', (opcional) read_opts}\n",
    "    \"main\": {\n",
    "        \"path\": RAW_DIR / \"dataset.csv\",\n",
    "        # \"format\": \"csv\",  # se omitir, detecta pelo sufixo\n",
    "        \"read_opts\": {\"encoding\": \"utf-8\", \"sep\": \",\", \"low_memory\": False}\n",
    "    },\n",
    "    # Exemplo de segunda fonte em CSV:\n",
    "    # \"dim_customers\": {\n",
    "    #   \"path\": RAW_DIR / \"exemplo.csv\",\n",
    "    #   \"format\": \"csv\",  # se omitir, detecta pelo sufixo\n",
    "    #   \"read_opts\": {\"encoding\": \"utf-8\", \"sep\": \",\", \"low_memory\": False}\n",
    "    # }\n",
    "    \n",
    "    # Exemplo de fonte em Parquet:\n",
    "    # \"dim_customers\": {\n",
    "    #     \"path\": RAW_DIR / \"customers.parquet\",\n",
    "    #     \"format\": \"parquet\"\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Plano de merges (opcional):\n",
    "# Cada item √© um passo: (right_name, how, left_on, right_on)\n",
    "# O DataFrame base ser√° o SOURCES[MAIN_SOURCE]\n",
    "MAIN_SOURCE = \"main\"\n",
    "MERGE_STEPS = [\n",
    "    # (\"dim_customers\", \"left\", \"customer_id\", \"id\"),\n",
    "]\n",
    "\n",
    "# Valida√ß√£o\n",
    "main_path = SOURCES[MAIN_SOURCE][\"path\"]\n",
    "main_format = SOURCES[MAIN_SOURCE].get(\"format\") or main_path.suffix.lstrip(\".\").lower()\n",
    "print(f\"‚úÖ Fontes configuradas com sucesso.\")\n",
    "\n",
    "print(\n",
    "    f\"‚Üí Fonte principal: '{MAIN_SOURCE}'  \"\n",
    "    f\"| Arquivo: {main_path.name}  \"\n",
    "    f\"| Formato detectado: {main_format.upper()}\"\n",
    ")\n",
    "if MERGE_STEPS:\n",
    "    print(f\"‚Üí {len(MERGE_STEPS)} etapa(s) de merge configuradas.\")\n",
    "else:\n",
    "    print(\"‚Üí Nenhum merge configurado (usando apenas a fonte principal).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aca992",
   "metadata": {},
   "source": [
    "## üì• Ingest√£o & Vis√£o R√°pida\n",
    "\n",
    "Nesta etapa, os **datasets definidos em `SOURCES`** s√£o carregados, inspecionados e validados antes de iniciar o tratamento dos dados.  \n",
    "O objetivo √© garantir que as fontes estejam corretamente lidas e que o DataFrame principal (`df`) esteja pronto para seguir no pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 1. Carregamento das fontes\n",
    "\n",
    "Cada item de `SOURCES` √© percorrido para:\n",
    "- Ler o arquivo indicado (`path`) conforme o formato (`csv` ou `parquet`);  \n",
    "- Aplicar as op√ß√µes de leitura (`read_opts`) definidas no dicion√°rio;  \n",
    "- Armazenar o DataFrame em `tables[name]`, onde `name` √© a chave de identifica√ß√£o da fonte.\n",
    "\n",
    "A fun√ß√£o utilizada √© `ud.load_table_simple()`, que automaticamente:\n",
    "- Detecta o formato pelo sufixo (se n√£o informado);\n",
    "- Aplica `read_opts` de forma segura;\n",
    "- Exibe logs amig√°veis durante o carregamento.\n",
    "\n",
    "Ap√≥s cada leitura, √© exibido um **resumo r√°pido** da fonte carregada, com:\n",
    "- N√∫mero de linhas e colunas;\n",
    "- Tipos de dados;\n",
    "- Uso de mem√≥ria;\n",
    "- E um relat√≥rio de valores nulos (`ud.missing_report()`).\n",
    "\n",
    "---\n",
    "\n",
    "### üîó 2. Defini√ß√£o do DataFrame base e jun√ß√µes opcionais\n",
    "\n",
    "O dataset principal √© definido pela vari√°vel `MAIN_SOURCE`.  \n",
    "Caso existam outras fontes configuradas em `MERGE_STEPS`, o notebook aplica as jun√ß√µes automaticamente via `ud.merge_chain()` ‚Äî garantindo que cada passo do merge seja logado e validado.\n",
    "\n",
    "Se nenhuma jun√ß√£o for configurada, o notebook utiliza apenas a fonte principal.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 3. Vis√£o geral final do DataFrame\n",
    "\n",
    "Ap√≥s a etapa de ingest√£o e merges, o notebook gera uma vis√£o consolidada do dataset final (`df`) que seguir√° no pipeline.  \n",
    "S√£o exibidos:\n",
    "- Estrutura geral (`shape`, colunas, tipos);\n",
    "- Quantidade de valores nulos por coluna;\n",
    "- E um log detalhado gravado em `reports/data_preparation.log`.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Exemplo de estrutura do processo\n",
    "\n",
    "```python\n",
    "tables = {}\n",
    "for name, cfg in SOURCES.items():\n",
    "    path = cfg[\"path\"]\n",
    "    fmt = cfg.get(\"format\")\n",
    "    read_opts = cfg.get(\"read_opts\", {})\n",
    "    df_src = ud.load_table_simple(path, fmt, **read_opts)\n",
    "    tables[name] = df_src\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    ov = ud.basic_overview(df_src)\n",
    "    print(json.dumps(ov, indent=2, ensure_ascii=False))\n",
    "    display(ud.missing_report(df_src).head(20))\n",
    "\n",
    "# Base principal e merges\n",
    "df = tables[MAIN_SOURCE]\n",
    "if MERGE_STEPS:\n",
    "    df = ud.merge_chain(df, tables, MERGE_STEPS)\n",
    "else:\n",
    "    print(f\"[INFO] Usando df base: '{MAIN_SOURCE}' (sem merges).\")\n",
    "\n",
    "# Overview final\n",
    "overview = ud.basic_overview(df)\n",
    "logger.info(json.dumps(overview, indent=2, ensure_ascii=False))\n",
    "display(ud.missing_report(df).head(20))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> - Cada fonte de dados √© carregada automaticamente com base na configura√ß√£o do dicion√°rio `SOURCES`.  \n",
    "> - A fun√ß√£o `ud.load_table_simple()` lida tanto com arquivos CSV quanto Parquet e detecta o formato automaticamente.  \n",
    "> - O dicion√°rio `tables` mant√©m todas as fontes acess√≠veis pelo nome definido (ex.: `\"main\"`, `\"dim_customers\"`).  \n",
    "> - A vari√°vel `df` representa o dataset principal que seguir√° pelas pr√≥ximas etapas do pipeline.  \n",
    "> - Logs e relat√≥rios s√£o salvos para garantir transpar√™ncia e rastreabilidade do processo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9753997b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\\utils_data.py\n",
      "1.2.2-merged\n",
      "\n",
      "=== main ===\n",
      "{\n",
      "  \"rows\": 7043,\n",
      "  \"cols\": 21,\n",
      "  \"dtypes\": {\n",
      "    \"customerID\": \"object\",\n",
      "    \"gender\": \"object\",\n",
      "    \"SeniorCitizen\": \"int64\",\n",
      "    \"Partner\": \"object\",\n",
      "    \"Dependents\": \"object\",\n",
      "    \"tenure\": \"int64\",\n",
      "    \"PhoneService\": \"object\",\n",
      "    \"MultipleLines\": \"object\",\n",
      "    \"InternetService\": \"object\",\n",
      "    \"OnlineSecurity\": \"object\",\n",
      "    \"OnlineBackup\": \"object\",\n",
      "    \"DeviceProtection\": \"object\",\n",
      "    \"TechSupport\": \"object\",\n",
      "    \"StreamingTV\": \"object\",\n",
      "    \"StreamingMovies\": \"object\",\n",
      "    \"Contract\": \"object\",\n",
      "    \"PaperlessBilling\": \"object\",\n",
      "    \"PaymentMethod\": \"object\",\n",
      "    \"MonthlyCharges\": \"float64\",\n",
      "    \"TotalCharges\": \"object\",\n",
      "    \"Churn\": \"object\"\n",
      "  },\n",
      "  \"memory_mb\": 6.821\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonthlyCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tenure</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SeniorCitizen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  missing_count  missing_pct\n",
       "0         customerID              0          0.0\n",
       "1   DeviceProtection              0          0.0\n",
       "2       TotalCharges              0          0.0\n",
       "3     MonthlyCharges              0          0.0\n",
       "4      PaymentMethod              0          0.0\n",
       "5   PaperlessBilling              0          0.0\n",
       "6           Contract              0          0.0\n",
       "7    StreamingMovies              0          0.0\n",
       "8        StreamingTV              0          0.0\n",
       "9        TechSupport              0          0.0\n",
       "10      OnlineBackup              0          0.0\n",
       "11            gender              0          0.0\n",
       "12    OnlineSecurity              0          0.0\n",
       "13   InternetService              0          0.0\n",
       "14     MultipleLines              0          0.0\n",
       "15      PhoneService              0          0.0\n",
       "16            tenure              0          0.0\n",
       "17        Dependents              0          0.0\n",
       "18           Partner              0          0.0\n",
       "19     SeniorCitizen              0          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Usando df base: 'main' (sem merges).\n",
      "2025-11-02 11:57:17,348 | INFO | {\n",
      "  \"rows\": 7043,\n",
      "  \"cols\": 21,\n",
      "  \"dtypes\": {\n",
      "    \"customerID\": \"object\",\n",
      "    \"gender\": \"object\",\n",
      "    \"SeniorCitizen\": \"int64\",\n",
      "    \"Partner\": \"object\",\n",
      "    \"Dependents\": \"object\",\n",
      "    \"tenure\": \"int64\",\n",
      "    \"PhoneService\": \"object\",\n",
      "    \"MultipleLines\": \"object\",\n",
      "    \"InternetService\": \"object\",\n",
      "    \"OnlineSecurity\": \"object\",\n",
      "    \"OnlineBackup\": \"object\",\n",
      "    \"DeviceProtection\": \"object\",\n",
      "    \"TechSupport\": \"object\",\n",
      "    \"StreamingTV\": \"object\",\n",
      "    \"StreamingMovies\": \"object\",\n",
      "    \"Contract\": \"object\",\n",
      "    \"PaperlessBilling\": \"object\",\n",
      "    \"PaymentMethod\": \"object\",\n",
      "    \"MonthlyCharges\": \"float64\",\n",
      "    \"TotalCharges\": \"object\",\n",
      "    \"Churn\": \"object\"\n",
      "  },\n",
      "  \"memory_mb\": 6.821\n",
      "}\n",
      "{\n",
      "  \"rows\": 7043,\n",
      "  \"cols\": 21,\n",
      "  \"dtypes\": {\n",
      "    \"customerID\": \"object\",\n",
      "    \"gender\": \"object\",\n",
      "    \"SeniorCitizen\": \"int64\",\n",
      "    \"Partner\": \"object\",\n",
      "    \"Dependents\": \"object\",\n",
      "    \"tenure\": \"int64\",\n",
      "    \"PhoneService\": \"object\",\n",
      "    \"MultipleLines\": \"object\",\n",
      "    \"InternetService\": \"object\",\n",
      "    \"OnlineSecurity\": \"object\",\n",
      "    \"OnlineBackup\": \"object\",\n",
      "    \"DeviceProtection\": \"object\",\n",
      "    \"TechSupport\": \"object\",\n",
      "    \"StreamingTV\": \"object\",\n",
      "    \"StreamingMovies\": \"object\",\n",
      "    \"Contract\": \"object\",\n",
      "    \"PaperlessBilling\": \"object\",\n",
      "    \"PaymentMethod\": \"object\",\n",
      "    \"MonthlyCharges\": \"float64\",\n",
      "    \"TotalCharges\": \"object\",\n",
      "    \"Churn\": \"object\"\n",
      "  },\n",
      "  \"memory_mb\": 6.821\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonthlyCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tenure</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SeniorCitizen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  missing_count  missing_pct\n",
       "0         customerID              0          0.0\n",
       "1   DeviceProtection              0          0.0\n",
       "2       TotalCharges              0          0.0\n",
       "3     MonthlyCharges              0          0.0\n",
       "4      PaymentMethod              0          0.0\n",
       "5   PaperlessBilling              0          0.0\n",
       "6           Contract              0          0.0\n",
       "7    StreamingMovies              0          0.0\n",
       "8        StreamingTV              0          0.0\n",
       "9        TechSupport              0          0.0\n",
       "10      OnlineBackup              0          0.0\n",
       "11            gender              0          0.0\n",
       "12    OnlineSecurity              0          0.0\n",
       "13   InternetService              0          0.0\n",
       "14     MultipleLines              0          0.0\n",
       "15      PhoneService              0          0.0\n",
       "16            tenure              0          0.0\n",
       "17        Dependents              0          0.0\n",
       "18           Partner              0          0.0\n",
       "19     SeniorCitizen              0          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, importlib\n",
    "sys.path.insert(0, r\"C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\utils\")\n",
    "\n",
    "import utils_data as ud\n",
    "importlib.reload(ud)\n",
    "\n",
    "print(ud.__file__)\n",
    "print(ud.UTILS_DATA_VERSION)  # deve mostrar 1.1.1\n",
    "\n",
    "\n",
    "# 1) Carregar todas as fontes\n",
    "tables = {}\n",
    "for name, cfg in SOURCES.items():\n",
    "    path = cfg[\"path\"]\n",
    "    fmt = cfg.get(\"format\")              # se None, detecta pelo sufixo\n",
    "    read_opts = cfg.get(\"read_opts\", {}) # ex.: sep/encoding/low_memory para CSV\n",
    "    df_src = ud.load_table_simple(path, fmt, **read_opts)  # agora com prefixo ud.\n",
    "    tables[name] = df_src\n",
    "\n",
    "    # vis√£o r√°pida por fonte\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    ov = ud.basic_overview(df_src)\n",
    "    print(json.dumps(ov, indent=2, ensure_ascii=False))\n",
    "    display(ud.missing_report(df_src).head(20))\n",
    "\n",
    "# 2) Definir df base e aplicar merges (se configurado)\n",
    "if MAIN_SOURCE not in tables:\n",
    "    raise KeyError(f\"MAIN_SOURCE '{MAIN_SOURCE}' n√£o encontrado. Fontes dispon√≠veis: {list(tables.keys())}\")\n",
    "\n",
    "df = tables[MAIN_SOURCE]\n",
    "if MERGE_STEPS:\n",
    "    df = ud.merge_chain(df, tables, MERGE_STEPS)\n",
    "    print(\"\\n=== Vis√£o geral (df merged) ===\")\n",
    "else:\n",
    "    print(f\"\\n[INFO] Usando df base: '{MAIN_SOURCE}' (sem merges).\")\n",
    "\n",
    "# 3) Overview final do df que segue no pipeline\n",
    "overview = ud.basic_overview(df)\n",
    "logger.info(json.dumps(overview, indent=2, ensure_ascii=False))\n",
    "print(json.dumps(overview, indent=2, ensure_ascii=False))\n",
    "display(ud.missing_report(df).head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132d3fd-de0e-4e93-9d3f-e5466a07b562",
   "metadata": {},
   "source": [
    "## üîñ Cat√°logo de DataFrames + df ‚Äúativo‚Äù\n",
    "\n",
    "Esta etapa cria um **cat√°logo centralizado de DataFrames** para gerenciar facilmente todas as tabelas carregadas e derivadas ao longo do projeto.  \n",
    "O objetivo √© permitir que diferentes vers√µes e transforma√ß√µes dos dados sejam armazenadas, nomeadas e acessadas de forma organizada e reprodut√≠vel.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 1. Inicializa√ß√£o do cat√°logo (`TableStore`)\n",
    "\n",
    "A classe `TableStore` (definida em `utils/utils_data.py`) atua como um **reposit√≥rio de DataFrames nomeados**.  \n",
    "Ela √© inicializada com o dicion√°rio `tables` (criado na etapa de *Ingest√£o & Vis√£o R√°pida*) e define a tabela principal (`MAIN_SOURCE`) como **tabela ativa**.\n",
    "\n",
    "Durante a inicializa√ß√£o, o notebook exibe uma mensagem de sucesso semelhante a esta:\n",
    "\n",
    "```\n",
    "‚úÖ Cat√°logo de DataFrames inicializado com sucesso.\n",
    "‚Üí Total de tabelas carregadas: 1\n",
    "‚Üí Tabela ativa: 'main'  | Shape: 7032 linhas √ó 21 colunas\n",
    "```\n",
    "\n",
    "E apresenta uma pr√©via do invent√°rio atual:\n",
    "\n",
    "| name | rows | cols | memory_mb |\n",
    "|------|------|-------|-----------|\n",
    "| main | 7032 | 21    | 1.2       |\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 2. Defini√ß√£o do DataFrame ativo (`df`)\n",
    "\n",
    "A vari√°vel `df` recebe a tabela atual atrav√©s de `T.get()`.  \n",
    "Esse `df` passa a representar o **DataFrame padr√£o** que seguir√° nas pr√≥ximas etapas do pipeline (limpeza, tipagem e transforma√ß√£o).\n",
    "\n",
    "---\n",
    "\n",
    "### üß© 3. Gerenciamento de m√∫ltiplas tabelas\n",
    "\n",
    "Novos DataFrames podem ser adicionados ao cat√°logo a qualquer momento, com nomes descritivos e controle de vers√£o.  \n",
    "O cat√°logo tamb√©m permite alternar entre tabelas e listar todas as dispon√≠veis.\n",
    "\n",
    "**Principais comandos:**\n",
    "\n",
    "```python\n",
    "T.add(\"churn_raw\", df, set_current=True)           # adiciona e define como atual\n",
    "df = T.use(\"churn_raw\")                            # alterna o df ativo\n",
    "T.add(\"features_v1\", engenharia_de_atributos(df))  # armazena uma nova deriva√ß√£o\n",
    "df_features = T[\"features_v1\"]                     # acesso direto por nome\n",
    "display(T.list())                                  # exibe o invent√°rio completo\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß† 4. Benef√≠cio pr√°tico\n",
    "\n",
    "- Mant√©m o notebook limpo e evita sobrescrever DataFrames importantes.  \n",
    "- Facilita o reuso e o rastreamento das vers√µes intermedi√°rias dos dados.  \n",
    "- Ideal para projetos com m√∫ltiplas fontes, transforma√ß√µes paralelas ou compara√ß√µes entre conjuntos tratados.  \n",
    "- Fornece feedback visual imediato sobre o estado do pipeline, tornando o fluxo mais transparente e interativo.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> O `TableStore` funciona como uma **mem√≥ria estruturada de DataFrames**, permitindo adicionar, alternar, versionar e consultar tabelas de forma controlada.  \n",
    "> A vari√°vel `df` representa sempre a **tabela ativa** atual, garantindo consist√™ncia nas etapas seguintes do pipeline e visibilidade sobre o progresso do processamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d35c12-157e-4677-8b08-8cb6f9571ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cat√°logo de DataFrames inicializado com sucesso.\n",
      "‚Üí Total de tabelas carregadas: 1\n",
      "‚Üí Tabela ativa: 'main'  | Shape: 7043 linhas √ó 21 colunas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>memory_mb</th>\n",
       "      <th>current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>7043</td>\n",
       "      <td>21</td>\n",
       "      <td>6.821</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  rows  cols  memory_mb  current\n",
       "0  main  7043    21      6.821     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.utils_data import TableStore\n",
    "\n",
    "# 1- Inicializa cat√°logo com as fontes lidas ('tables') e define a base como atual\n",
    "T = TableStore(initial=tables, current=MAIN_SOURCE)\n",
    "\n",
    "# 2 - Conveni√™ncia: df = tabela atual (boa pr√°tica para seguir no pipeline)\n",
    "df = T.get()\n",
    "\n",
    "# 3 - Feedback visual de sucesso\n",
    "print(f\"‚úÖ Cat√°logo de DataFrames inicializado com sucesso.\")\n",
    "print(f\"‚Üí Total de tabelas carregadas: {len(tables)}\")\n",
    "print(f\"‚Üí Tabela ativa: '{T.current}'  | Shape: {df.shape[0]} linhas √ó {df.shape[1]} colunas\")\n",
    "\n",
    "# 4Ô∏è4 - Exibe uma pr√©via do cat√°logo\n",
    "display(T.list().head())\n",
    "\n",
    "# --- Guia r√°pido  ---\n",
    "# T.add(\"churn_raw\", df, set_current=True)          # cadastra e ativa\n",
    "# df = T.use(\"churn_raw\")                           # muda o atual e retorna df\n",
    "# T.add(\"features_v1\", engenharia_de_atributos(df)) # salva uma deriva√ß√£o\n",
    "# df_features = T[\"features_v1\"]                    # acesso direto por nome\n",
    "# display(T.list())                                 # invent√°rio das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "714e2ee7-bfcb-426b-80e3-eada5cd60941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "0  No phone service             DSL             No          Yes   \n",
       "1                No             DSL            Yes           No   \n",
       "2                No             DSL            Yes          Yes   \n",
       "3  No phone service             DSL            Yes           No   \n",
       "4                No     Fiber optic             No           No   \n",
       "\n",
       "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0               No          No          No              No  Month-to-month   \n",
       "1              Yes          No          No              No        One year   \n",
       "2               No          No          No              No  Month-to-month   \n",
       "3              Yes         Yes          No              No        One year   \n",
       "4               No          No          No              No  Month-to-month   \n",
       "\n",
       "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \\\n",
       "0              Yes           Electronic check           29.85        29.85   \n",
       "1               No               Mailed check           56.95       1889.5   \n",
       "2              Yes               Mailed check           53.85       108.15   \n",
       "3               No  Bank transfer (automatic)           42.30      1840.75   \n",
       "4              Yes           Electronic check           70.70       151.65   \n",
       "\n",
       "  Churn  \n",
       "0    No  \n",
       "1    No  \n",
       "2   Yes  \n",
       "3    No  \n",
       "4   Yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c23859a",
   "metadata": {},
   "source": [
    "## üß™ Qualidade & Tipagem\n",
    "\n",
    "Nesta etapa o notebook realiza a **padroniza√ß√£o estrutural e tipagem autom√°tica dos dados**, garantindo que o DataFrame principal (`df`) siga para as pr√≥ximas fases **coerente, limpo e otimizado em mem√≥ria**.  \n",
    "√â uma das fases mais cr√≠ticas do pipeline, pois evita que inconsist√™ncias de tipo e formato prejudiquem as an√°lises posteriores ou a modelagem.\n",
    "\n",
    "### üìã O que √© feito aqui\n",
    "\n",
    "1. **Remo√ß√£o de espa√ßos em branco (`strip_whitespace`)**\n",
    "   - Elimina espa√ßos extras no in√≠cio e no fim de valores textuais.  \n",
    "   - Evita diverg√™ncias em compara√ß√µes e agrupamentos (ex.: `\"Yes \"` ‚â† `\"Yes\"`).  \n",
    "   - Essa opera√ß√£o √© **idempotente**: se os dados j√° estiverem limpos, n√£o altera nada.\n",
    "\n",
    "2. **Convers√£o inteligente de valores num√©ricos (`infer_numeric_like`)**\n",
    "   - Detecta colunas com valores *aparentemente num√©ricos*, mas armazenados como texto (ex.: `\"R$ 120,00\"` ou `\"1.234,56\"`).  \n",
    "   - Aplica heur√≠sticas para remover s√≠mbolos, normalizar separadores e converter apenas quando a propor√ß√£o de convers√£o for suficiente (`min_ratio = 0.9`).  \n",
    "   - Evita convers√µes indevidas (ex.: IDs) por meio de uma lista de exclus√£o (`blacklist`).  \n",
    "   - Gera o relat√≥rio **`cast_report`**, registrando:\n",
    "     - Coluna analisada  \n",
    "     - A√ß√£o tomada (convertida, ignorada ou parcial)  \n",
    "     - Taxa de sucesso e total de valores convertidos.\n",
    "\n",
    "3. **Otimiza√ß√£o de tipos num√©ricos (`reduce_memory_usage`)**\n",
    "   - Converte automaticamente `int64` ‚Üí `int32` e `float64` ‚Üí `float32`, reduzindo o consumo de mem√≥ria sem alterar os valores.  \n",
    "   - O log mostra a diferen√ßa antes e depois (ex.: `Memory reduced: 7.76MB ‚Üí 6.21MB`).\n",
    "\n",
    "4. **Remo√ß√£o de duplicatas (`deduplicate_rows`)**\n",
    "   - Verifica e elimina registros repetidos conforme a configura√ß√£o (`subset`, `keep`).  \n",
    "   - Caso encontre duplicatas, gera um relat√≥rio detalhado e salva o log em `reports/duplicates.csv`.  \n",
    "   - Exibe uma amostra das duplicatas detectadas, se houver.\n",
    "\n",
    "5. **Relat√≥rios e feedback autom√°tico**\n",
    "   - Ao final da execu√ß√£o, exibe um resumo completo:  \n",
    "     - Linhas e colunas antes/depois  \n",
    "     - Varia√ß√£o de mem√≥ria (`Œî MB`)  \n",
    "     - Relat√≥rios gerados (`cast_report`, `duplicates_report`, etc.)  \n",
    "   - Todos os logs s√£o gravados em `reports/data_preparation.log`.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula garante que o dataset esteja **consistente, tipado e otimizado**, pronto para an√°lises e modelagem.  \n",
    "> Corrige formata√ß√µes, converte n√∫meros armazenados como texto, remove duplicatas e reduz o uso de mem√≥ria ‚Äî tudo com registros autom√°ticos e relat√≥rios salvos para auditoria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e16822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:22,765 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:22,780 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='n1_quality_typing:start' registrado.\n",
      "2025-11-02 11:57:22,783 | INFO | [manifest] step='n1_quality_typing:start' registrado.\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:22,907 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:22,914 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:22,926 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-02 11:57:22,929 | INFO | [manifest] step='save_report_df' registrado.\n",
      "[INFO] [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\cast_report.csv (18 linhas)\n",
      "2025-11-02 11:57:22,931 | INFO | [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\cast_report.csv (18 linhas)\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:22,933 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:22,944 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='n1_quality_typing:end' registrado.\n",
      "2025-11-02 11:57:22,946 | INFO | [manifest] step='n1_quality_typing:end' registrado.\n",
      "üìÑ Convers√µes num√©ricas (amostra):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>converted_non_null</th>\n",
       "      <th>introduced_nans</th>\n",
       "      <th>dtype_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>7032</td>\n",
       "      <td>11</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Churn</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  converted_non_null  introduced_nans dtype_after\n",
       "16      TotalCharges                7032               11     float64\n",
       "0         customerID                   0             7043      object\n",
       "1             gender                   0             7043      object\n",
       "15     PaymentMethod                   0             7043      object\n",
       "14  PaperlessBilling                   0             7043      object\n",
       "13          Contract                   0             7043      object\n",
       "12   StreamingMovies                   0             7043      object\n",
       "11       StreamingTV                   0             7043      object\n",
       "10       TechSupport                   0             7043      object\n",
       "9   DeviceProtection                   0             7043      object\n",
       "8       OnlineBackup                   0             7043      object\n",
       "7     OnlineSecurity                   0             7043      object\n",
       "6    InternetService                   0             7043      object\n",
       "5      MultipleLines                   0             7043      object\n",
       "4       PhoneService                   0             7043      object\n",
       "3         Dependents                   0             7043      object\n",
       "2            Partner                   0             7043      object\n",
       "17             Churn                   0             7043      object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Nenhuma duplicidade encontrada segundo os crit√©rios definidos.\n",
      "\n",
      "‚úÖ Qualidade & Tipagem conclu√≠do com sucesso!\n",
      "‚Üí Shape: (7043, 21) ‚Üí (7043, 21) (Œîlinhas=+0, Œîcolunas=+0)\n",
      "‚Üí Mem√≥ria: 6.82 MB ‚Üí 6.51 MB (Œî=-0.31 MB)\n",
      "‚Üí Relat√≥rios gerados: cast_report, df\n"
     ]
    }
   ],
   "source": [
    "# Qualidade & Tipagem (compat√≠vel com ambas as APIs)\n",
    "\n",
    "df_before_shape = df.shape\n",
    "mem_before = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "\n",
    "# ‚ö†Ô∏è Importante: N√ÉO passe paths.reports_dir como 'root', pois isso duplicar√° 'reports/reports'.\n",
    "# Deixe o utils resolver a raiz do projeto internamente.\n",
    "if hasattr(ud, \"n1_quality_typing_dict\"):\n",
    "    out = ud.n1_quality_typing_dict(df, config)   # sempre retorna dict\n",
    "    df  = out[\"df\"]\n",
    "    rep = out\n",
    "else:\n",
    "    df, rep = ud.n1_quality_typing(df, config)    # retorna (df, meta_dict)\n",
    "\n",
    "mem_after  = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "delta_rows = df.shape[0] - df_before_shape[0]\n",
    "delta_cols = df.shape[1] - df_before_shape[1]\n",
    "delta_mem  = mem_after - mem_before\n",
    "\n",
    "# Exibe relat√≥rios √∫teis (se existirem)\n",
    "cast_report = rep.get(\"cast_report\") if isinstance(rep, dict) else None\n",
    "if isinstance(cast_report, pd.DataFrame) and not cast_report.empty:\n",
    "    print(\"üìÑ Convers√µes num√©ricas (amostra):\")\n",
    "    display(cast_report.head(20))\n",
    "\n",
    "dups = rep.get(\"duplicates\") if isinstance(rep, dict) else None\n",
    "if isinstance(dups, pd.DataFrame) and not dups.empty:\n",
    "    print(\"\\nüîÅ Duplicatas detectadas (amostra):\")\n",
    "    display(dups.head(10))\n",
    "    dsum = rep.get(\"duplicates_summary\") if isinstance(rep, dict) else None\n",
    "    if isinstance(dsum, pd.DataFrame) and not dsum.empty:\n",
    "        print(\"üìä Resumo por chave:\")\n",
    "        display(dsum.head(20))\n",
    "else:\n",
    "    print(\"\\n‚úÖ Nenhuma duplicidade encontrada segundo os crit√©rios definidos.\")\n",
    "\n",
    "# Mensagem de sucesso consolidada\n",
    "reported_keys = []\n",
    "if isinstance(rep, dict):\n",
    "    for k, v in rep.items():\n",
    "        if isinstance(v, pd.DataFrame) and not v.empty:\n",
    "            reported_keys.append(k)\n",
    "\n",
    "print(\n",
    "    f\"\\n‚úÖ Qualidade & Tipagem conclu√≠do com sucesso!\\n\"\n",
    "    f\"‚Üí Shape: {df_before_shape} ‚Üí {df.shape} (Œîlinhas={delta_rows:+}, Œîcolunas={delta_cols:+})\\n\"\n",
    "    f\"‚Üí Mem√≥ria: {mem_before:.2f} MB ‚Üí {mem_after:.2f} MB (Œî={delta_mem:+.2f} MB)\\n\"\n",
    "    f\"‚Üí Relat√≥rios gerados: {', '.join(reported_keys) if reported_keys else '‚Äî'}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00dd1f3-27f8-402a-95da-b3faf39b0efc",
   "metadata": {},
   "source": [
    "## üßº Padroniza√ß√£o Categ√≥rica\n",
    "\n",
    "Nesta etapa ocorre a **padroniza√ß√£o global de r√≥tulos textuais** em colunas categ√≥ricas, corrigindo inconsist√™ncias, diferen√ßas de capitaliza√ß√£o e valores redundantes (como `\"No internet service\"` ‚Üí `\"No\"`).  \n",
    "O objetivo √© **garantir uniformidade sem alterar o significado dos dados**, preparando o dataset para codifica√ß√£o e modelagem.\n",
    "\n",
    "---\n",
    "\n",
    "### üìã O que √© feito aqui\n",
    "\n",
    "1. **Sele√ß√£o autom√°tica das colunas categ√≥ricas**  \n",
    "   - S√£o processadas todas as colunas com tipo `object`, `string` ou `category`, exceto aquelas listadas em `exclude` (ex.: `\"customerID\"`).\n",
    "\n",
    "2. **Limpeza e normaliza√ß√£o de forma**  \n",
    "   - Remove espa√ßos extras (`trim`) e consolida espa√ßos duplos (`collapse_ws`).  \n",
    "   - Corrige capitaliza√ß√£o conforme o par√¢metro `case` (`\"title\"`, `\"lower\"`, `\"upper\"`, `\"none\"`).  \n",
    "   - Opcionalmente remove acentos (`strip_accents`).\n",
    "\n",
    "3. **Substitui√ß√µes e valores nulos**  \n",
    "   - Aplica um mapa global de substitui√ß√µes (`global_map`) para corrigir padr√µes conhecidos (ex.: `\"No internet service\"` ‚Üí `\"No\"`).  \n",
    "   - Permite tamb√©m um mapa espec√≠fico por coluna (`per_column_map`), quando necess√°rio.  \n",
    "   - Converte valores definidos em `null_values` (ex.: `\"n/a\"`, `\"na\"`, `\"-\"`) em `NaN`.\n",
    "\n",
    "4. **Convers√£o opcional para categoria**  \n",
    "   - Se `cast_to_category=True`, converte colunas textuais em `category`, otimizando uso de mem√≥ria.\n",
    "\n",
    "5. **Gera√ß√£o de relat√≥rio e registro autom√°tico**  \n",
    "   - Cria o arquivo `cat_normalization.csv` dentro da pasta `reports/`, com:  \n",
    "     - Nome da coluna  \n",
    "     - Amostras antes/depois  \n",
    "     - Quantidade de altera√ß√µes (`changes`)  \n",
    "     - N√∫mero de categorias √∫nicas antes/depois  \n",
    "   - As informa√ß√µes tamb√©m s√£o registradas no log e adicionadas ao `manifest.json`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Configura√ß√£o (`CAT_NORM_CFG`)\n",
    "\n",
    "A padroniza√ß√£o √© controlada por um dicion√°rio de configura√ß√£o completo:\n",
    "\n",
    "```python\n",
    "CAT_NORM_CFG = {\n",
    "    \"enabled\": True,\n",
    "    \"exclude\": [\"customerID\"],\n",
    "    \"case\": \"title\",\n",
    "    \"strip_accents\": True,\n",
    "    \"collapse_ws\": True,\n",
    "    \"trim\": True,\n",
    "    \"global_map\": {\n",
    "        \"No internet service\": \"No\",\n",
    "        \"No phone service\": \"No\",\n",
    "        \"n/a\": \"No\",\n",
    "        \"none\": \"No\"\n",
    "    },\n",
    "    \"null_values\": [\"\", \"na\", \"n/a\", \"-\"],\n",
    "    \"cast_to_category\": False\n",
    "}\n",
    "```\n",
    "\n",
    "Exemplo de mapa espec√≠fico por coluna:\n",
    "```python\n",
    "\"per_column_map\": {\n",
    "    \"InternetService\": {\"Dsl\": \"DSL\", \"Fiber Optic\": \"Fiber Optic\"}\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula realiza uma **padroniza√ß√£o inteligente e audit√°vel** das colunas categ√≥ricas ‚Äî aplicando limpeza, substitui√ß√µes e normaliza√ß√£o de forma sistem√°tica.  \n",
    "> O processo √© controlado via configura√ß√£o (`CAT_NORM_CFG`), gera um relat√≥rio autom√°tico e mant√©m registro completo no log e no `manifest.json`, garantindo **clareza, rastreabilidade e consist√™ncia** no tratamento dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b83f96-33a7-4589-970e-9406d75eaaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:43,288 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:43,302 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-02 11:57:43,303 | INFO | [manifest] step='save_report_df' registrado.\n",
      "üìë Relat√≥rio de padroniza√ß√£o (top 20 por mudan√ßas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contract</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>5517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Churn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  changed\n",
       "0           Contract     7043\n",
       "1      PaymentMethod     7043\n",
       "2    InternetService     5517\n",
       "3     OnlineSecurity     1526\n",
       "4       OnlineBackup     1526\n",
       "5   DeviceProtection     1526\n",
       "6        TechSupport     1526\n",
       "7        StreamingTV     1526\n",
       "8    StreamingMovies     1526\n",
       "9      MultipleLines      682\n",
       "10            gender        0\n",
       "11           Partner        0\n",
       "12        Dependents        0\n",
       "13      PhoneService        0\n",
       "14  PaperlessBilling        0\n",
       "15             Churn        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Padroniza√ß√£o Categ√≥rica conclu√≠da (fun√ß√£o avan√ßada)\n",
      "‚Üí Shape: (7043, 21) ‚Üí (7043, 21) (Œîlinhas=+0, Œîcolunas=+0)\n",
      "‚Üí Mem√≥ria: 6.51 MB ‚Üí 6.51 MB (Œî=+0.00 MB)\n",
      "‚Üí Relat√≥rio salvo em: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\cat_normalization.csv\n"
     ]
    }
   ],
   "source": [
    "# Config gen√©rica de normaliza√ß√£o (ajuste √† vontade)\n",
    "CAT_NORM_CFG = {\n",
    "    \"enabled\": True,\n",
    "    \"exclude\": [\"customerID\"],          # nunca normalizar IDs\n",
    "    \"case\": \"title\",                    # \"lower\" | \"upper\" | \"title\"\n",
    "    \"strip_accents\": True,\n",
    "    \"collapse_ws\": True,\n",
    "    \"trim\": True,\n",
    "    \"global_map\": {\n",
    "        \"No internet service\": \"No\",\n",
    "        \"No phone service\": \"No\",\n",
    "        \"n/a\": \"No\",\n",
    "        \"none\": \"No\"\n",
    "    },\n",
    "    \"null_values\": [\"\", \"na\", \"n/a\", \"-\"],\n",
    "    \"cast_to_category\": False,\n",
    "    # \"per_column_map\": {\"PaperlessBilling\": {\"sim\": \"Yes\", \"nao\": \"No\"}}\n",
    "}\n",
    "\n",
    "# Guarda m√©tricas antes/depois\n",
    "_before_shape = df.shape\n",
    "_before_mem   = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "\n",
    "# Caminho de relat√≥rio\n",
    "cat_report_path = paths.reports_dir / \"cat_normalization.csv\"\n",
    "\n",
    "# Tentativa 1: usar a fun√ß√£o avan√ßada (com cfg e relat√≥rio)\n",
    "_used_fallback = False\n",
    "try:\n",
    "    df_norm, cat_norm_report = ud.normalize_categories(\n",
    "        df,\n",
    "        cfg=CAT_NORM_CFG,\n",
    "        report_path=cat_report_path  # aten√ß√£o: √© um caminho completo; essa fun√ß√£o j√° lida com Path\n",
    "    )\n",
    "except TypeError:\n",
    "    # Tentativa 2: fallback para vers√£o simples do utils (sem cfg, sem report interno)\n",
    "    _used_fallback = True\n",
    "\n",
    "    # Limita √†s colunas de texto e aplica \"exclude\" da config\n",
    "    text_cols = [c for c in df.columns if df[c].dtype == \"object\" or pd.api.types.is_string_dtype(df[c])]\n",
    "    target_cols = [c for c in text_cols if c not in set(CAT_NORM_CFG.get(\"exclude\", []))]\n",
    "\n",
    "    df_before = df.copy()\n",
    "\n",
    "    # Chamada da vers√£o simples\n",
    "    df_norm = ud.normalize_categories(\n",
    "        df,\n",
    "        cols=target_cols,\n",
    "        case=CAT_NORM_CFG.get(\"case\", \"lower\"),\n",
    "        trim=CAT_NORM_CFG.get(\"trim\", True),\n",
    "        strip_accents=CAT_NORM_CFG.get(\"strip_accents\", True),\n",
    "    )\n",
    "\n",
    "    # Se a fun√ß√£o simples retornar s√≥ o df, mantenha:\n",
    "    if isinstance(df_norm, tuple):\n",
    "        # alguma variante pode retornar (df, report); normaliza para df apenas\n",
    "        df_norm = df_norm[0]\n",
    "\n",
    "    # Constr√≥i um relat√≥rio equivalente (diferen√ßas por coluna)\n",
    "    changes = []\n",
    "    for c in target_cols:\n",
    "        changed = (df_before[c].astype(str) != df_norm[c].astype(str)).sum()\n",
    "        if changed > 0:\n",
    "            changes.append({\"column\": c, \"changed\": int(changed)})\n",
    "\n",
    "    cat_norm_report = pd.DataFrame(changes).sort_values(\"changed\", ascending=False).reset_index(drop=True)\n",
    "    cat_report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cat_norm_report.to_csv(cat_report_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Atualiza o df do pipeline\n",
    "df = df_norm\n",
    "\n",
    "# M√©tricas p√≥s\n",
    "_after_mem   = float(df.memory_usage(deep=True).sum() / (1024**2))\n",
    "_delta_rows  = df.shape[0] - _before_shape[0]\n",
    "_delta_cols  = df.shape[1] - _before_shape[1]\n",
    "_delta_mem   = _after_mem - _before_mem\n",
    "\n",
    "# Exibi√ß√£o do relat√≥rio\n",
    "if isinstance(cat_norm_report, pd.DataFrame) and not cat_norm_report.empty:\n",
    "    print(\"üìë Relat√≥rio de padroniza√ß√£o (top 20 por mudan√ßas):\")\n",
    "    display(cat_norm_report.head(20))\n",
    "else:\n",
    "    print(\"‚úÖ Nenhuma mudan√ßa significativa detectada nas colunas categ√≥ricas.\")\n",
    "\n",
    "# Mensagem consolidada\n",
    "print(\n",
    "    f\"\\n‚úÖ Padroniza√ß√£o Categ√≥rica conclu√≠da \"\n",
    "    f\"{'(fallback simples)' if _used_fallback else '(fun√ß√£o avan√ßada)'}\\n\"\n",
    "    f\"‚Üí Shape: {_before_shape} ‚Üí {df.shape} (Œîlinhas={_delta_rows:+}, Œîcolunas={_delta_cols:+})\\n\"\n",
    "    f\"‚Üí Mem√≥ria: {_before_mem:.2f} MB ‚Üí {_after_mem:.2f} MB (Œî={_delta_mem:+.2f} MB)\\n\"\n",
    "    f\"‚Üí Relat√≥rio salvo em: {cat_report_path}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569d5cd",
   "metadata": {},
   "source": [
    "## ü©π Tratamento de Valores Faltantes\n",
    "\n",
    "Nesta etapa s√£o tratadas as **aus√™ncias de dados** (valores nulos ou `NaN`) para garantir que o DataFrame siga consistente para as pr√≥ximas fases do pipeline.  \n",
    "O objetivo √© **preencher ou sinalizar valores faltantes** de forma controlada, preservando a integridade estat√≠stica das colunas e registrando quais linhas foram modificadas.\n",
    "\n",
    "### üìã O que √© feito aqui\n",
    "\n",
    "1. **Gera√ß√£o de relat√≥rio inicial**\n",
    "   - Exibe um diagn√≥stico das colunas com valores ausentes, mostrando a propor√ß√£o (`missing_rate`) e o total (`missing_count`) de registros nulos.\n",
    "   - Essa visualiza√ß√£o ajuda a decidir se o tratamento ser√° simples ou se exigir√° t√©cnicas espec√≠ficas.\n",
    "\n",
    "2. **Aplica√ß√£o da estrat√©gia de imputa√ß√£o**\n",
    "   - O comportamento √© controlado pela chave `missing_strategy` do arquivo de configura√ß√£o:\n",
    "     - `\"simple\"` ‚Üí aplica a fun√ß√£o `simple_impute_with_flags()`\n",
    "     - `\"advanced\"` ‚Üí reservado para m√©todos personalizados (ex.: KNN, regress√£o, interpola√ß√£o)\n",
    "   - A estrat√©gia **simples** executa:\n",
    "     - Substitui√ß√£o de valores nulos **num√©ricos** pela **mediana** da coluna.  \n",
    "     - Substitui√ß√£o de valores nulos **categ√≥ricos** pela **moda** (valor mais frequente).  \n",
    "   - Durante a imputa√ß√£o, s√£o criadas **colunas de flag** no formato `was_imputed_<coluna>`, indicando quais linhas foram alteradas.\n",
    "\n",
    "3. **Relat√≥rio final de verifica√ß√£o**\n",
    "   - Ap√≥s o preenchimento, √© exibido novamente o relat√≥rio de faltantes para confirmar se todas as lacunas foram resolvidas.\n",
    "   - Caso ainda existam colunas cr√≠ticas, o notebook pode ser ajustado para aplicar m√©todos mais avan√ßados.\n",
    "\n",
    "### Exemplo de flag gerada:\n",
    "| customerID | TotalCharges | was_imputed_TotalCharges |\n",
    "|-------------|--------------|--------------------------|\n",
    "| 7590-VHVEG  | 29.85        | False                   |\n",
    "| 9237-HQITU  | 1840.75      | True                    |\n",
    "\n",
    "Linhas com `True` indicam que o valor original estava ausente e foi imputado automaticamente.\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula identifica e corrige valores faltantes, aplicando regras de imputa√ß√£o simples e registrando onde cada substitui√ß√£o ocorreu.  \n",
    "> Isso garante **transpar√™ncia, rastreabilidade e controle de qualidade**, permitindo filtrar posteriormente apenas os dados considerados consistentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04728790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:52,408 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:52,411 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:52,424 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-02 11:57:52,427 | INFO | [manifest] step='save_report_df' registrado.\n",
      "[INFO] [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\missing\\before.csv (21 linhas)\n",
      "2025-11-02 11:57:52,430 | INFO | [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\missing\\before.csv (21 linhas)\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:52,486 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:52,489 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "2025-11-02 11:57:52,502 | INFO | PROJECT_ROOT: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\n",
      "[INFO] [manifest] step='save_report_df' registrado.\n",
      "2025-11-02 11:57:52,504 | INFO | [manifest] step='save_report_df' registrado.\n",
      "[INFO] [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\missing\\after.csv (42 linhas)\n",
      "2025-11-02 11:57:52,506 | INFO | [report] salvo: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\missing\\after.csv (42 linhas)\n",
      "\n",
      "‚úÖ Tratamento de faltantes conclu√≠do!\n",
      "‚Üí Estrat√©gia final: simple\n",
      "‚Üí Colunas imputadas (amostra): ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'customerID', 'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines']\n",
      "\n",
      "Relat√≥rio de faltantes (antes):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>11</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeviceProtection</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonthlyCharges</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PaperlessBilling</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StreamingMovies</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StreamingTV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TechSupport</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OnlineBackup</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OnlineSecurity</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InternetService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tenure</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Partner</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SeniorCitizen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  missing_count  missing_pct\n",
       "0       TotalCharges             11         0.16\n",
       "1         customerID              0         0.00\n",
       "2   DeviceProtection              0         0.00\n",
       "3     MonthlyCharges              0         0.00\n",
       "4      PaymentMethod              0         0.00\n",
       "5   PaperlessBilling              0         0.00\n",
       "6           Contract              0         0.00\n",
       "7    StreamingMovies              0         0.00\n",
       "8        StreamingTV              0         0.00\n",
       "9        TechSupport              0         0.00\n",
       "10      OnlineBackup              0         0.00\n",
       "11            gender              0         0.00\n",
       "12    OnlineSecurity              0         0.00\n",
       "13   InternetService              0         0.00\n",
       "14     MultipleLines              0         0.00\n",
       "15      PhoneService              0         0.00\n",
       "16            tenure              0         0.00\n",
       "17        Dependents              0         0.00\n",
       "18           Partner              0         0.00\n",
       "19     SeniorCitizen              0         0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relat√≥rio de faltantes (depois):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InternetService_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MonthlyCharges_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TotalCharges_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customerID_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gender_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Partner_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dependents_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PhoneService_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultipleLines_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OnlineSecurity_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OnlineBackup_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DeviceProtection_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TechSupport_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>StreamingTV_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>StreamingMovies_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Contract_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PaperlessBilling_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PaymentMethod_was_missing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          column  missing_count  missing_pct\n",
       "0                     customerID              0          0.0\n",
       "1    InternetService_was_missing              0          0.0\n",
       "2     MonthlyCharges_was_missing              0          0.0\n",
       "3       TotalCharges_was_missing              0          0.0\n",
       "4         customerID_was_missing              0          0.0\n",
       "5             gender_was_missing              0          0.0\n",
       "6            Partner_was_missing              0          0.0\n",
       "7         Dependents_was_missing              0          0.0\n",
       "8       PhoneService_was_missing              0          0.0\n",
       "9      MultipleLines_was_missing              0          0.0\n",
       "10    OnlineSecurity_was_missing              0          0.0\n",
       "11                        gender              0          0.0\n",
       "12      OnlineBackup_was_missing              0          0.0\n",
       "13  DeviceProtection_was_missing              0          0.0\n",
       "14       TechSupport_was_missing              0          0.0\n",
       "15       StreamingTV_was_missing              0          0.0\n",
       "16   StreamingMovies_was_missing              0          0.0\n",
       "17          Contract_was_missing              0          0.0\n",
       "18  PaperlessBilling_was_missing              0          0.0\n",
       "19     PaymentMethod_was_missing              0          0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === N1 ¬∑ Tratamento de Valores Faltantes (compacto) =========================\n",
    "import importlib, utils.utils_data as ud\n",
    "importlib.reload(ud)\n",
    "\n",
    "# Garante df como DataFrame caso alguma etapa tenha retornado tupla\n",
    "df = ud.coerce_df(df)\n",
    "\n",
    "res = ud.handle_missing_step(\n",
    "    df,\n",
    "    config=config,                     # usa config[\"missing\"] ou chaves antigas\n",
    "    save_reports=True,                 # salva before/after em reports/missing/\n",
    "    prefer=\"auto\"                      # \"auto\" tenta strategy do config e faz fallback p/ simple\n",
    ")\n",
    "\n",
    "df = res[\"df\"]\n",
    "\n",
    "print(\"\\n‚úÖ Tratamento de faltantes conclu√≠do!\")\n",
    "print(f\"‚Üí Estrat√©gia final: {res['strategy']}\")\n",
    "print(f\"‚Üí Colunas imputadas (amostra): {res.get('imputed_cols', [])[:10] or '‚Äî'}\")\n",
    "\n",
    "from IPython.display import display\n",
    "print(\"\\nRelat√≥rio de faltantes (antes):\")\n",
    "display(res[\"before\"].head(20))\n",
    "\n",
    "print(\"\\nRelat√≥rio de faltantes (depois):\")\n",
    "display(res[\"after\"].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc838d6",
   "metadata": {},
   "source": [
    "## üö© Detec√ß√£o de Outliers\n",
    "\n",
    "Esta etapa identifica **valores at√≠picos** nas colunas num√©ricas, adicionando colunas de flag (`*_is_outlier`) que indicam quais registros se desviam do padr√£o estat√≠stico esperado.  \n",
    "Essas colunas servem para **inspe√ß√£o e auditoria**, sem alterar ou remover dados ‚Äî a decis√£o de tratamento posterior (ajuste, exclus√£o ou manuten√ß√£o) √© **de neg√≥cio**.\n",
    "\n",
    "### ‚öôÔ∏è Como funciona\n",
    "\n",
    "1. **Verifica a configura√ß√£o**\n",
    "   - A execu√ß√£o depende da flag `detect_outliers` no arquivo `config/defaults.json`.  \n",
    "     Se estiver definida como `true`, a detec√ß√£o √© realizada.\n",
    "\n",
    "2. **Seleciona o m√©todo estat√≠stico**\n",
    "   - `\"iqr\"` ‚Üí usa o **Intervalo Interquartil (Interquartile Range)**:\n",
    "     - Calcula Q1 (25¬∫ percentil) e Q3 (75¬∫ percentil)\n",
    "     - Define limites:  \n",
    "       Inferior = Q1 ‚àí 1.5 √ó IQR  \n",
    "       Superior = Q3 + 1.5 √ó IQR\n",
    "     - Valores fora desse intervalo s√£o marcados como outliers.\n",
    "   - `\"zscore\"` ‚Üí usa o **desvio-padr√£o (Z-Score)**:\n",
    "     - Calcula a m√©dia (Œº) e o desvio-padr√£o (œÉ)\n",
    "     - Para cada valor, obt√©m `z = (x ‚àí Œº) / œÉ`\n",
    "     - Valores com |z| > 3 s√£o considerados outliers.\n",
    "\n",
    "3. **Cria√ß√£o de colunas de flag**\n",
    "   - Para cada vari√°vel num√©rica analisada, √© criada uma nova coluna:\n",
    "     ```\n",
    "     <coluna>_is_outlier\n",
    "     ```\n",
    "   - O valor ser√°:\n",
    "     - `True` ‚Üí registro identificado como outlier  \n",
    "     - `False` ‚Üí registro dentro do intervalo esperado\n",
    "\n",
    "4. **Registro no log**\n",
    "   - Ao final, o sistema registra no log quantas colunas de flag foram criadas:\n",
    "     ```\n",
    "     Outlier flags created: 4\n",
    "     ```\n",
    "     Significa que 4 colunas num√©ricas foram analisadas e receberam suas respectivas flags.\n",
    "\n",
    "### Exemplo de resultado\n",
    "\n",
    "| tenure | MonthlyCharges | TotalCharges | tenure_is_outlier | MonthlyCharges_is_outlier | TotalCharges_is_outlier |\n",
    "|--------|----------------|--------------|-------------------|----------------------------|--------------------------|\n",
    "| 5      | 35.50          | 190.00       | False             | False                      | False                    |\n",
    "| 72     | 120.00         | 9999.99      | False             | **True**                   | **True**                 |\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula adiciona colunas de marca√ß√£o para detectar valores at√≠picos de acordo com o m√©todo configurado.  \n",
    "> Os dados originais s√£o preservados, permitindo que a an√°lise posterior defina se esses registros devem ser **mantidos, ajustados ou removidos**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1338f2eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils.utils_data' has no attribute 'apply_outlier_flags'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df, out_info \u001b[38;5;241m=\u001b[39m ud\u001b[38;5;241m.\u001b[39mapply_outlier_flags(df, config\u001b[38;5;241m=\u001b[39mconfig, persist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutlier flags created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_flags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# vis√£o r√°pida\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'utils.utils_data' has no attribute 'apply_outlier_flags'"
     ]
    }
   ],
   "source": [
    "df, out_info = ud.apply_outlier_flags(df, config=config, persist=True)\n",
    "logger.info(f\"Outlier flags created: {out_info['created_flags']}\")\n",
    "# vis√£o r√°pida\n",
    "if out_info['created_flags'] > 0:\n",
    "    display(\n",
    "        df.filter(like=\"_is_outlier\")\n",
    "          .sum()\n",
    "          .sort_values(ascending=False)\n",
    "          .to_frame(\"outliers_count\")\n",
    "          .head(20)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e0c7d5-5fc8-4a90-b531-0cb7885e88a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(df\u001b[38;5;241m.\u001b[39mfilter(like\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_outlier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'filter'"
     ]
    }
   ],
   "source": [
    "display(df.filter(like=\"_is_outlier\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b431b",
   "metadata": {},
   "source": [
    "## üß¨ Duplicidades\n",
    "\n",
    "Remove **linhas duplicadas** do DataFrame para evitar contagens infladas, vieses e ru√≠do em m√©tricas.\n",
    "\n",
    "### üìã O que acontece aqui\n",
    "- Por padr√£o, a duplicidade √© verificada **linha a linha** (todas as colunas iguais).  \n",
    "- A primeira ocorr√™ncia √© mantida e as demais s√£o removidas.\n",
    "\n",
    "### üîß Op√ß√µes (se configuradas no `config`)\n",
    "- `deduplicate_subset`: lista de colunas que definem a chave de deduplica√ß√£o  \n",
    "  *Ex.:* `[\"customerID\"]` mant√©m apenas um registro por cliente.\n",
    "- `deduplicate_keep`: pol√≠tica de reten√ß√£o ‚Äî `\"first\"`, `\"last\"` ou `false` (remove todas as repeti√ß√µes).\n",
    "- `deduplicate_log` + `deduplicate_log_filename`: salva um **CSV** com as duplicatas detectadas em `reports/`.\n",
    "\n",
    "### Boas pr√°ticas:\n",
    "- Uso do `subset` quando a duplicidade for **conceitual** (ex.: mesma pessoa/pedido), n√£o necessariamente toda a linha id√™ntica.\n",
    "- Gerar e revisar o relat√≥rio de duplicatas antes de decidir pela remo√ß√£o definitiva.\n",
    "\n",
    "> üí°**Resumo:** esta etapa garante um dataset **sem registros repetidos** segundo o crit√©rio definido, mantendo rastreabilidade quando o log estiver habilitado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f8aee5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deduplicate_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeduplicate\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m deduplicate_rows(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'deduplicate_rows' is not defined"
     ]
    }
   ],
   "source": [
    "if config['deduplicate']:\n",
    "    df = deduplicate_rows(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dc0ea",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Engenharia de Atributos\n",
    "\n",
    "Cria√ß√£o de novas colunas que capturem **rela√ß√µes, propor√ß√µes, categorias ou padr√µes** relevantes ao neg√≥cio.  \n",
    "Essa etapa √© inteiramente manual e depende do contexto do dataset.\n",
    "\n",
    "### üí° Exemplos:\n",
    "- **Raz√µes e propor√ß√µes:** `TotalCharges / tenure` ‚Üí gasto m√©dio mensal.  \n",
    "- **Flags categ√≥ricas:** `Contract == 'Month-to-month'` ‚Üí 1 se contrato mensal.  \n",
    "- **Contagens de servi√ßos:** soma de colunas bin√°rias (Yes/No).  \n",
    "\n",
    "Essas novas features tornam as an√°lises mais ricas e **melhoram a performance de modelos preditivos**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4296c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['feature_engineering']:\n",
    "    # Exemplo gen√©rico (comente/remova conforme o caso):\n",
    "    # if {'col_a','col_b'}.issubset(df.columns):\n",
    "    #     df['a_per_b'] = df['col_a'] / df['col_b'].replace(0, np.nan)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a1c18",
   "metadata": {},
   "source": [
    "# üìÖ Tratamento de Datas\n",
    "\n",
    "Esta etapa detecta e converte colunas de datas de forma **autom√°tica e controlada**, criando **features temporais** √∫teis para an√°lises e modelos preditivos.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã O que acontece aqui\n",
    "\n",
    "### üîπ Identifica√ß√£o de colunas de data\n",
    "\n",
    "O sistema procura automaticamente colunas com nomes que contenham termos como  \n",
    "`date`, `data`, `dt_`, `_dt`, ou `_date`.\n",
    "\n",
    "Tamb√©m √© poss√≠vel **for√ßar colunas espec√≠ficas** definindo manualmente em:\n",
    "\n",
    "```python\n",
    "date_cfg[\"explicit_cols\"] = [\"StartDate\", \"EndDate\"]\n",
    "```\n",
    "\n",
    "### üîπ Convers√£o para datetime com auditoria\n",
    "\n",
    "Cada coluna candidata √© testada com diferentes formatos e tentativas de *parsing*.  \n",
    "O relat√≥rio **`parse_report`** mostra:\n",
    "\n",
    "| column      | parsed_ratio | converted |\n",
    "|--------------|--------------|------------|\n",
    "| order_date   | 1.00         | True       |\n",
    "| start_date   | 0.35         | False      |\n",
    "\n",
    "- **column:** nome da coluna testada  \n",
    "- **parsed_ratio:** porcentagem de valores convertidos com sucesso  \n",
    "- **converted:** indica se a coluna foi convertida (baseado no `min_ratio`)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Cria√ß√£o autom√°tica de features temporais\n",
    "\n",
    "Para cada coluna convertida em `datetime`, s√£o geradas vari√°veis derivadas como:\n",
    "\n",
    "`*_year`, `*_month`, `*_day`, `*_dayofweek`, `*_quarter`, `*_week`,  \n",
    "`*_is_month_start`, `*_is_month_end`\n",
    "\n",
    "O prefixo das novas colunas √© o **nome original da coluna de data** .\n",
    "\n",
    "---\n",
    "\n",
    "### üß± Comportamento defensivo\n",
    "\n",
    "Caso nenhuma coluna seja detectada, a c√©lula n√£o gera erro ‚Äî apenas loga:\n",
    "\n",
    "`[dates] Nenhuma coluna de data detectada/convertida. Pule a cria√ß√£o de features.`\n",
    "\n",
    "\n",
    "Assim, o pipeline segue normalmente.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Configura√ß√£o (`date_cfg`)\n",
    "\n",
    "| Par√¢metro       | Descri√ß√£o                                                        | Exemplo               |\n",
    "|-----------------|------------------------------------------------------------------|------------------------|\n",
    "| `detect_regex`  | Padr√£o para localizar colunas com nomes de data                 | `\"date\"`              |\n",
    "| `explicit_cols` | Lista manual de colunas a converter                             | `[\"StartDate\"]`       |\n",
    "| `dayfirst`      | Define se o formato √© D/M/Y                                     | `True` para üáßüá∑        |\n",
    "| `utc`           | Define se a convers√£o deve ser em UTC                           | `False`               |\n",
    "| `formats`       | Lista de formatos espec√≠ficos                                   | `[\"%d/%m/%Y\"]`        |\n",
    "| `min_ratio`     | Fra√ß√£o m√≠nima de parsing bem-sucedido para aceitar a convers√£o  | `0.8`                 |\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula realiza o reconhecimento autom√°tico de colunas de data,\n",
    "converte-as para o formato datetime e gera vari√°veis derivadas como\n",
    "ano, m√™s, dia e semana.\n",
    "> Caso nenhuma coluna de data seja encontrada, o c√≥digo √© ignorado com seguran√ßa,\n",
    "garantindo a continuidade do pipeline sem erros.\n",
    "> Os par√¢metros em date_cfg permitem ajustar formato, localiza√ß√£o e toler√¢ncia\n",
    "de parsing conforme a estrutura de cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14c4c15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 06:01:19,351 | INFO | [dates] candidates=[]\n",
      "2025-10-30 06:01:19,352 | INFO | [dates] parsed_ok=[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>parsed_ratio</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column, parsed_ratio, converted]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 06:01:19,356 | INFO | [dates] Nenhuma coluna de data detectada/convertida. Pule a cria√ß√£o de features.\n"
     ]
    }
   ],
   "source": [
    "date_cfg = {\n",
    "  \"detect_regex\": r\"(date|data|dt_|_dt$|_date$)\",\n",
    "  \"explicit_cols\": [],   # ex.: [\"StartDate\",\"EndDate\"]\n",
    "  \"dayfirst\": False,     # True se datas forem D/M/Y\n",
    "  \"utc\": False,\n",
    "  \"formats\": [],         # ex.: [\"%d/%m/%Y\", \"%Y-%m-%d\"]\n",
    "  \"min_ratio\": 0.80,\n",
    "}\n",
    "\n",
    "\n",
    "# Converter e auditar parsing\n",
    "df, parse_report, parsed_cols = parse_dates_with_report(df, date_cfg)\n",
    "display(parse_report)\n",
    "\n",
    "if not parsed_cols:\n",
    "    logger.info(\"[dates] Nenhuma coluna de data detectada/convertida. Pule a cria√ß√£o de features.\")\n",
    "else:\n",
    "    created = expand_date_features(\n",
    "        df, parsed_cols,\n",
    "        features=[\"year\",\"month\",\"day\",\"dayofweek\",\"quarter\",\"week\",\"is_month_start\",\"is_month_end\"],\n",
    "        prefix_mode=\"auto\"\n",
    "    )\n",
    "    logger.info(f\"[dates] features criadas: {len(created)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0ad24-b7dc-4e36-98f9-97f790b7aafa",
   "metadata": {},
   "source": [
    "# üóìÔ∏è Cria√ß√£o da Tabela Calend√°rio (`dim_date`)\n",
    "\n",
    "Esta etapa gera automaticamente uma **tabela calend√°rio completa** ‚Äî tamb√©m chamada de **dimens√£o de tempo** ‚Äî a partir de uma coluna de datas existente no dataset principal.  \n",
    "A tabela √© √∫til para **an√°lises temporais, dashboards e modelos de previs√£o** que utilizam per√≠odos como refer√™ncia (ano, m√™s, trimestre, etc).\n",
    "\n",
    "---\n",
    "\n",
    "## üìã O que acontece aqui\n",
    "\n",
    "### üîπ Sele√ß√£o da coluna de data\n",
    "\n",
    "Voc√™ define manualmente qual coluna ser√° usada como base:\n",
    "\n",
    "```python\n",
    "CAL_DATE_COL = \"order_date\"  # nome da coluna datetime escolhida\n",
    "CAL_FREQ = \"D\"               # frequ√™ncia: \"D\" (di√°rio), \"W\" (semanal), \"M\" (mensal)\n",
    "```\n",
    "\n",
    "A coluna deve estar no formato **datetime**.  \n",
    "Se n√£o estiver, ser√° exibido um erro pedindo para executar antes a etapa de **Tratamento de Datas**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Gera√ß√£o da dimens√£o calend√°rio\n",
    "\n",
    "A fun√ß√£o `build_calendar_from()` constr√≥i uma tabela com todas as datas entre o **m√≠nimo** e o **m√°ximo** encontrados em `CAL_DATE_COL`.\n",
    "\n",
    "Para cada data, s√£o criadas colunas derivadas, como:\n",
    "\n",
    "| Coluna          | Descri√ß√£o                                |\n",
    "|------------------|-------------------------------------------|\n",
    "| `date`           | Data base (chave principal)              |\n",
    "| `year`           | Ano                                      |\n",
    "| `month`          | M√™s num√©rico                             |\n",
    "| `day`            | Dia do m√™s                               |\n",
    "| `quarter`        | Trimestre (1‚Äì4)                          |\n",
    "| `week`           | Semana do ano (ISO)                      |\n",
    "| `dow`            | Dia da semana (0 = segunda, 6 = domingo) |\n",
    "| `is_month_start` | Indica se a data √© o primeiro dia do m√™s |\n",
    "| `is_month_end`   | Indica se a data √© o √∫ltimo dia do m√™s   |\n",
    "| `month_name`     | Nome do m√™s                              |\n",
    "| `day_name`       | Nome do dia da semana                    |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Armazenamento e reuso\n",
    "\n",
    "A tabela √© salva automaticamente no diret√≥rio de artefatos (`artifacts/`):\n",
    "\n",
    "```python\n",
    "CAL_OUT = ARTIFACTS_DIR / \"dim_date.csv\"\n",
    "```\n",
    "\n",
    "O formato √© determinado pela extens√£o (.csv ou .parquet).\n",
    "Al√©m disso, a tabela pode ser registrada no cat√°logo de DataFrames (T) para uso posterior no pipeline:\n",
    "```python\n",
    "T.add(\"dim_date\", dim_date)\n",
    "```\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula cria uma dimens√£o de tempo completa baseada na coluna de data escolhida.\n",
    "> Ela facilita compara√ß√µes e agrega√ß√µes por ano, m√™s, semana ou trimestre, al√©m de permitir jun√ß√µes temporais consistentes com outros datasets ou dashboards (ex.: Power BI).\n",
    "> O processo √© autom√°tico, reproduz√≠vel e independente do dataset principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb7f1368-d692-4703-a297-5298e186e576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Coluna 'order_date' n√£o encontrada no DataFrame. Ajuste CAL_DATE_COL para uma coluna v√°lida antes de gerar a tabela calend√°rio.\n",
      "2025-10-30 06:01:24,339 | WARNING | ‚ö†Ô∏è Coluna 'order_date' n√£o encontrada no DataFrame. Ajuste CAL_DATE_COL para uma coluna v√°lida antes de gerar a tabela calend√°rio.\n"
     ]
    }
   ],
   "source": [
    "# Ajuste estes par√¢metros conforme o dataset:\n",
    "CAL_DATE_COL = \"order_date\"           # escolha aqui a coluna de datas j√° convertida para datetime\n",
    "CAL_FREQ     = \"D\"                    # \"D\" (di√°rio), \"W\" (semanal), \"M\" (mensal) etc.\n",
    "CAL_OUT      = ARTIFACTS_DIR / \"dim_date.csv\"  # caminho de sa√≠da (csv/parquet conforme a extens√£o)\n",
    "\n",
    "# --- valida√ß√µes suaves ---\n",
    "if CAL_DATE_COL not in df.columns:\n",
    "    msg = f\"‚ö†Ô∏è Coluna '{CAL_DATE_COL}' n√£o encontrada no DataFrame. \" \\\n",
    "          f\"Ajuste CAL_DATE_COL para uma coluna v√°lida antes de gerar a tabela calend√°rio.\"\n",
    "    print(msg)\n",
    "    logger.warning(msg)\n",
    "else:\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[CAL_DATE_COL]):\n",
    "        msg = f\"‚ö†Ô∏è Coluna '{CAL_DATE_COL}' existe, mas **n√£o est√° em formato datetime**. \" \\\n",
    "              \"Execute a etapa de Tratamento de Datas antes, ou converta manualmente.\"\n",
    "        print(msg)\n",
    "        logger.warning(msg)\n",
    "    else:\n",
    "        # --- constru√ß√£o da dimens√£o calend√°rio ---\n",
    "        dim_date = build_calendar_from(df, CAL_DATE_COL, freq=CAL_FREQ)\n",
    "\n",
    "        # --- vis√£o r√°pida ---\n",
    "        display(dim_date.head(12))\n",
    "        start_date = dim_date[\"date\"].min()\n",
    "        end_date   = dim_date[\"date\"].max()\n",
    "        print(f\"Per√≠odo: {start_date.date()} ‚Üí {end_date.date()}  | Linhas: {len(dim_date)}\")\n",
    "\n",
    "        # --- salvar em disco respeitando a extens√£o do caminho ---\n",
    "        save_table(dim_date, CAL_OUT)\n",
    "        logger.info(f\"[calendar] Tabela calend√°rio salva em: {CAL_OUT}\")\n",
    "\n",
    "        # --- opcional: registrar no cat√°logo de tabelas ---\n",
    "        try:\n",
    "            T.add(\"dim_date\", dim_date)\n",
    "            logger.info(\"[calendar] 'dim_date' registrada no cat√°logo T.\")\n",
    "        except NameError:\n",
    "            # Se TableStore (T) n√£o estiver sendo usado nesta sess√£o, ignore.\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf4856",
   "metadata": {},
   "source": [
    "# üìù Tratamento de Texto (opcional)\n",
    "\n",
    "Esta etapa extrai **m√©tricas num√©ricas e l√≥gicas a partir de colunas textuais**, transformando texto livre em informa√ß√µes quantitativas √∫teis para **an√°lise explorat√≥ria e modelagem**.  \n",
    "\n",
    "√â uma forma leve e controlada de **estruturar dados n√£o num√©ricos**, sem recorrer a t√©cnicas avan√ßadas de NLP.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã O que acontece aqui\n",
    "\n",
    "### üîπ Identifica√ß√£o de colunas textuais\n",
    "\n",
    "O sistema busca automaticamente colunas com tipo `object` e ignora aquelas listadas na *blacklist*:\n",
    "\n",
    "```python\n",
    "text_cols = [c for c in df.columns if df[c].dtype == 'object' and c not in TEXT_CFG[\"blacklist\"]]\n",
    "```\n",
    "\n",
    "Essas colunas normalmente cont√™m informa√ß√µes como:  \n",
    "descri√ß√µes, coment√°rios, nomes, categorias textuais ou observa√ß√µes.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Limpeza e padroniza√ß√£o\n",
    "\n",
    "Antes de gerar as m√©tricas, os textos passam por uma limpeza leve:\n",
    "- Remo√ß√£o de **espa√ßos duplicados** e **trim** nas extremidades.  \n",
    "- Convers√£o para **min√∫sculas**, garantindo consist√™ncia em an√°lises de termos.\n",
    "\n",
    "Essas a√ß√µes s√£o controladas pelas chaves:\n",
    "```python\n",
    "\"lower\": True,\n",
    "\"strip_collapse_ws\": True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Cria√ß√£o autom√°tica de m√©tricas textuais\n",
    "\n",
    "Para cada coluna textual, s√£o geradas novas colunas num√©ricas:\n",
    "\n",
    "| Nova Coluna           | Descri√ß√£o | Exemplo (\"This is great!\") |\n",
    "|------------------------|------------|-----------------------------|\n",
    "| `<coluna>_len`         | N√∫mero total de caracteres no texto | 15 |\n",
    "| `<coluna>_word_count`  | N√∫mero de palavras separadas por espa√ßos | 3 |\n",
    "| `<coluna>_alpha_count` | N√∫mero de letras (A‚ÄìZ, a‚Äìz) | 13 |\n",
    "| `<coluna>_digit_count` | N√∫mero de d√≠gitos num√©ricos | 0 |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Presen√ßa de termos-chave\n",
    "\n",
    "O sistema tamb√©m cria colunas booleanas (`True` / `False`) para identificar a **ocorr√™ncia de palavras espec√≠ficas** em cada coluna textual.  \n",
    "\n",
    "Exemplo:\n",
    "```python\n",
    "TEXT_CFG[\"keywords\"] = [\"error\", \"cancel\", \"premium\"]\n",
    "```\n",
    "\n",
    "Gera colunas como:\n",
    "- `<coluna>_has_error`  \n",
    "- `<coluna>_has_cancel`  \n",
    "- `<coluna>_has_premium`\n",
    "\n",
    "Essas vari√°veis s√£o √∫teis para an√°lises de sentimento ou padr√µes de ocorr√™ncia em feedbacks de clientes.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Exporta√ß√£o de resumo\n",
    "\n",
    "Ao final, √© gerado um **resumo CSV** com as colunas de texto processadas e suas features derivadas.  \n",
    "O arquivo √© salvo em:\n",
    "```\n",
    "reports/text_features/summary.csv\n",
    "```\n",
    "\n",
    "Esse relat√≥rio documenta as transforma√ß√µes aplicadas, garantindo **rastreabilidade e transpar√™ncia**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Configura√ß√£o (`TEXT_CFG`)\n",
    "\n",
    "| Par√¢metro              | Descri√ß√£o                                                       | Exemplo                              |\n",
    "|------------------------|------------------------------------------------------------------|--------------------------------------|\n",
    "| `lower`                | Converte o texto para min√∫sculas                                | `True`                               |\n",
    "| `strip_collapse_ws`    | Remove espa√ßos duplicados e limpa extremidades                  | `True`                               |\n",
    "| `keywords`             | Lista de termos a detectar no texto                             | `[\"error\", \"cancel\", \"premium\"]`     |\n",
    "| `blacklist`            | Colunas a ignorar durante o processamento                       | `[\"customerID\"]`                     |\n",
    "| `export_summary`       | Salva relat√≥rio com resumo das features geradas                 | `True`                               |\n",
    "\n",
    "---\n",
    "\n",
    "### Boas pr√°ticas\n",
    "\n",
    "- Aplicar esta etapa apenas em colunas realmente textuais ‚Äî evite IDs ou c√≥digos.  \n",
    "- Personalizar a lista de **palavras-chave** conforme o contexto do dataset.  \n",
    "- Caso o dataset n√£o possua colunas de texto, o processo ser√° ignorado com seguran√ßa.  \n",
    "- Utilize o arquivo de resumo (`summary.csv`) para acompanhar colunas derivadas e auditorias.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula transforma campos de texto em **indicadores num√©ricos e l√≥gicos**, gerando m√©tricas b√°sicas (tamanho, palavras, letras, d√≠gitos) e flags de presen√ßa de termos-chave.  \n",
    "> Tudo √© processado automaticamente com **configura√ß√£o leve e reprodut√≠vel**, integrando dados textuais ao pipeline de forma organizada e escal√°vel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae0f5bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 08:36:56,991 | INFO | [text] colunas processadas: ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn']\n",
      "2025-10-30 08:36:56,992 | INFO | [text] features criadas: 112\n",
      "2025-10-30 08:36:57,006 | INFO | [text] resumo salvo em: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\text_features\\summary.csv\n",
      "üìù Resumo das colunas textuais (amostra):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>keywords_cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>gender_has_error, gender_has_cancel, gender_ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Partner</td>\n",
       "      <td>Partner_has_error, Partner_has_cancel, Partner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dependents</td>\n",
       "      <td>Dependents_has_error, Dependents_has_cancel, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PhoneService</td>\n",
       "      <td>PhoneService_has_error, PhoneService_has_cance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultipleLines</td>\n",
       "      <td>MultipleLines_has_error, MultipleLines_has_can...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_col                                      keywords_cols\n",
       "0         gender  gender_has_error, gender_has_cancel, gender_ha...\n",
       "1        Partner  Partner_has_error, Partner_has_cancel, Partner...\n",
       "2     Dependents  Dependents_has_error, Dependents_has_cancel, D...\n",
       "3   PhoneService  PhoneService_has_error, PhoneService_has_cance...\n",
       "4  MultipleLines  MultipleLines_has_error, MultipleLines_has_can..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEXT_CFG = {\n",
    "    \"lower\": True,\n",
    "    \"strip_collapse_ws\": True,\n",
    "    \"keywords\": [\"error\", \"cancel\", \"premium\"],\n",
    "    \"blacklist\": [\"customerID\"],\n",
    "    \"export_summary\": True,\n",
    "}\n",
    "\n",
    "if config.get(\"text_features\", True):\n",
    "    df, text_summary = extract_text_features(\n",
    "        df,\n",
    "        lower=TEXT_CFG[\"lower\"],\n",
    "        strip_collapse_ws=TEXT_CFG[\"strip_collapse_ws\"],\n",
    "        keywords=TEXT_CFG[\"keywords\"],\n",
    "        blacklist=TEXT_CFG[\"blacklist\"],\n",
    "        export_summary=TEXT_CFG[\"export_summary\"],\n",
    "        summary_dir=REPORTS_DIR / \"text_features\"\n",
    "    )\n",
    "    display(text_summary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc2bc7f",
   "metadata": {},
   "source": [
    "# üî§ Codifica√ß√£o de Categ√≥ricas & üî¢ Escalonamento Num√©rico (opcionais)\n",
    "\n",
    "Esta etapa transforma vari√°veis **categ√≥ricas** em representa√ß√µes num√©ricas e **padroniza a escala** das vari√°veis **num√©ricas** quando necess√°rio.  \n",
    "√â √∫til para alimentar modelos de ML que **n√£o aceitam strings** (ex.: regress√µes, SVMs, redes neurais) e/ou **s√£o sens√≠veis √† escala** (KNN, SVM com kernel RBF, PCA, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### üß≠ Vis√£o Geral\n",
    "\n",
    "- **Codifica√ß√£o (Encoding)**\n",
    "  - **One-hot**: cria uma coluna por categoria (0/1). √â a op√ß√£o **mais segura** para baseline; evita ordenar categorias artificialmente.\n",
    "  - **Ordinal**: mapeia categorias para n√∫meros inteiros. Mais **compacto**, mas induz **ordem artificial**; use com cuidado.\n",
    "\n",
    "- **Escalonamento (Scaling)**\n",
    "  - **Standard**: `z = (x - m√©dia) / desvio`; centra em 0 com vari√¢ncia ‚âà 1. Bom para dados **aprox. gaussianos**.\n",
    "  - **MinMax**: escala para **[0, 1]**; √∫til quando limites m√≠nimos e m√°ximos s√£o relevantes (redes neurais, normaliza√ß√µes simples).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Configura√ß√£o usada no notebook\n",
    "\n",
    "Estas configura√ß√µes s√£o lidas do `config/defaults.json` (com `local.json` sobrepondo, se existir) e s√£o repassadas como dicion√°rios para a fun√ß√£o `apply_encoding_and_scaling`:\n",
    "\n",
    "```python\n",
    "ENCODE_CFG = {\n",
    "    \"enabled\":           config.get(\"encode_categoricals\", True),\n",
    "    \"type\":              config.get(\"encoding_type\", \"onehot\"),  # \"onehot\" | \"ordinal\"\n",
    "    \"exclude_cols\":      [\"Churn\", \"customerID\"],                # N√ÉO codificar alvo/ids\n",
    "    \"high_card_threshold\": 50,                                    # ignora colunas com cardinalidade muito alta\n",
    "}\n",
    "\n",
    "SCALE_CFG = {\n",
    "    \"enabled\":           config.get(\"scale_numeric\", False),\n",
    "    \"method\":            config.get(\"scaler\", \"standard\"),       # \"standard\" | \"minmax\"\n",
    "    \"exclude_cols\":      [\"Churn\"],                              # N√ÉO escalar alvo\n",
    "    \"only_continuous\":   True,                                   # evita escalar dummies e inteiros-discretos\n",
    "}\n",
    "\n",
    "df, encoding_meta, scaling_meta = apply_encoding_and_scaling(\n",
    "    df, encode_cfg=ENCODE_CFG, scale_cfg=SCALE_CFG\n",
    ")\n",
    "```\n",
    "\n",
    "> üí° **Dica:** deixe `scale_numeric = false` no in√≠cio do projeto (explora√ß√£o/entendimento). Ative a escala somente quando partir para a **modelagem** e **valida√ß√£o**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© O que a fun√ß√£o faz (alto n√≠vel)\n",
    "\n",
    "1. **Seleciona colunas categ√≥ricas** (`object`/`category`) **excluindo** as listadas em `exclude_cols` e as com **cardinalidade > high_card_threshold** (prote√ß√£o contra explos√£o de dummies).\n",
    "2. **Codifica** conforme `type`:\n",
    "   - `onehot` ‚Üí gera `get_dummies` com `dtype=float` e concatena ao DataFrame (removendo as originais).\n",
    "   - `ordinal` ‚Üí aplica `OrdinalEncoder` do scikit-learn (com `unknown_value=-1`).\n",
    "3. **Escala colunas num√©ricas** se `SCALE_CFG[\"enabled\"]`:\n",
    "   - seleciona **apenas** colunas num√©ricas **cont√≠nuas** quando `only_continuous=True` (float/large-range).\n",
    "   - aplica `StandardScaler` **ou** `MinMaxScaler`.\n",
    "4. Retorna:\n",
    "   - `df` (atualizado),\n",
    "   - `encoding_meta` (categorias vistas, tipo de codifica√ß√£o, colunas exclu√≠das, descartes por cardinalidade),\n",
    "   - `scaling_meta` (tipo de escala, colunas escaladas, par√¢metros do scaler).\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Sa√≠das e Metadados\n",
    "\n",
    "- **`encoding_meta`** inclui:\n",
    "  - `encoding`: `\"onehot\"` **ou** `\"ordinal\"`\n",
    "  - `excluded`: lista de colunas ignoradas (ex.: `[\"Churn\",\"customerID\"]`)\n",
    "  - `high_card_excluded`: colunas **n√£o encodadas** por alta cardinalidade\n",
    "  - `categorical_columns`: colunas categ√≥ricas processadas\n",
    "  - (para ordinal) `categories_`: categorias aprendidas por coluna\n",
    "\n",
    "- **`scaling_meta`** inclui:\n",
    "  - `scaler`: `\"standard\"` **ou** `\"minmax\"`\n",
    "  - `scaled_columns`: lista das colunas escaladas\n",
    "  - `means_`/`scales_` (para Standard) **ou** `min_`/`range_` (para MinMax) ‚Äî √∫teis para **reprodu√ß√£o** no deploy\n",
    "\n",
    "Esses metadados s√£o importantes para **reaplicar** transforma√ß√µes de forma consistente em produ√ß√£o (ou na infer√™ncia).\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Exemplo de comportamento esperado\n",
    "\n",
    "Suponha um dataset com colunas:\n",
    "- `gender` (`Male`/`Female`), `InternetService` (3 categorias), `MonthlyCharges` (float), `tenure` (int), `Churn` (alvo).\n",
    "\n",
    "Com `onehot` + `standard` e exclus√µes padr√£o, o resultado ser√°:\n",
    "- Novas colunas como `gender_Female`, `gender_Male`, `InternetService_DSL`, etc.\n",
    "- `MonthlyCharges` escalado (m√©dia‚âà0, desvio‚âà1), `tenure` **pode** ser ignorado se `only_continuous=True` e for considerado discreto.\n",
    "\n",
    "---\n",
    "\n",
    "### üöß Armadilhas comuns e prote√ß√µes do template\n",
    "\n",
    "- **Explos√£o de dummies**: colunas com **muitas categorias** s√£o ignoradas (registro em `high_card_excluded`).\n",
    "- **Vazar o alvo**: `exclude_cols` deve conter a **target** (ex.: `\"Churn\"`).\n",
    "- **IDs**: evite codificar/escale IDs (`customerID`); eles n√£o carregam sem√¢ntica √∫til.\n",
    "- **Mixed types**: colunas mal tipadas (n√∫mero como string) devem ser tratadas antes (use a c√©lula **Qualidade & Tipagem**).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Status de execu√ß√£o e logs\n",
    "\n",
    "Ao executar, voc√™ ver√° mensagens no log do tipo:\n",
    "\n",
    "```\n",
    "[encode] type=onehot | cols=['gender', 'InternetService'] | high_card_excluded=[]\n",
    "[scale] method=standard | scaled_cols=['MonthlyCharges']\n",
    "```\n",
    "\n",
    "Se o log mostrar `cols=[]`, significa que **n√£o h√° colunas categ√≥ricas** eleg√≠veis (ou foram exclu√≠das por configura√ß√£o/cardinalidade). Isso √© **normal** em alguns datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Boas pr√°ticas\n",
    "\n",
    "- Comecar com **one-hot** e **sem escala** para ter uma baseline interpret√°vel.\n",
    "- Ativar **ordinal** apenas quando existir **ordem natural** nas categorias.\n",
    "- Escalonar **depois** de separar **treino/valida√ß√£o** para evitar vazamento (no template, esta etapa √© opcional e controlada por flag).\n",
    "- Guardar `encoding_meta` e `scaling_meta` se for levar o modelo para produ√ß√£o.\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Resumo:**  \n",
    "> Esta c√©lula converte dados categ√≥ricos e num√©ricos em formatos ideais para modelagem, mantendo controle sobre exclus√µes, cardinalidade e escala ‚Äî garantindo robustez, consist√™ncia e clareza no tratamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ebb07b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 06:05:32,736 | INFO | [text] colunas processadas: []\n",
      "2025-10-30 06:05:32,737 | INFO | [text] features criadas: 0\n",
      "2025-10-30 06:05:32,744 | INFO | [text] resumo salvo em: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\reports\\text_features\\summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib, utils.utils_data as ud\n",
    "importlib.reload(ud)  # garante a vers√£o mais recente\n",
    "\n",
    "TEXT_CFG = {\n",
    "    \"lower\": True,\n",
    "    \"strip_collapse_ws\": True,\n",
    "    \"keywords\": [\"error\", \"cancel\", \"premium\"],\n",
    "    \"blacklist\": [\"customerID\"],\n",
    "    \"export_summary\": True,\n",
    "}\n",
    "\n",
    "if config.get(\"text_features\", True):\n",
    "    df, text_summary = ud.extract_text_features(\n",
    "        df,\n",
    "        lower=TEXT_CFG[\"lower\"],\n",
    "        strip_collapse_ws=TEXT_CFG[\"strip_collapse_ws\"],\n",
    "        keywords=TEXT_CFG[\"keywords\"],\n",
    "        blacklist=TEXT_CFG[\"blacklist\"],\n",
    "        export_summary=TEXT_CFG[\"export_summary\"],\n",
    "        summary_dir=REPORTS_DIR / \"text_features\"\n",
    "    )\n",
    "    display(text_summary.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fdfbc03-691c-43bc-88ba-b346d3a30395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRIA√á√ÉO DE COLUNA TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66c7b008-28cc-4e03-ad5d-38e4cf78ad51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 06:05:34,838 | INFO | [target] 'target' criado de 'Churn' ‚Üí pos=1869 neg=5174 nulls=0 total=7043\n",
      "[target] Definido target_column='target' (fonte='Churn')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_col</th>\n",
       "      <th>target_col</th>\n",
       "      <th>dtype</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "      <th>nulls</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Churn</td>\n",
       "      <td>target</td>\n",
       "      <td>int</td>\n",
       "      <td>1869</td>\n",
       "      <td>5174</td>\n",
       "      <td>0</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_col target_col dtype  positives  negatives  nulls  total\n",
       "0      Churn     target   int       1869       5174      0   7043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cria o target a partir da config (ou defaults)\n",
    "df, target_name, class_map, tgt_report = ud.ensure_target_from_config(df, config, verbose=True)\n",
    "\n",
    "# Opcional: ver um mini-relat√≥rio\n",
    "display(tgt_report)\n",
    "\n",
    "# Garantir que o N2 enxergue o mapeamento, se voc√™ quiser usar class_map l√°:\n",
    "globals()[\"class_map\"] = class_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5827a7",
   "metadata": {},
   "source": [
    "## üíæ Exporta√ß√£o de Artefatos\n",
    "\n",
    "Salve dados **intermedi√°rios** e **prontos** para uso em modelagem/visualiza√ß√£o.  \n",
    "Tamb√©m salvamos um **manifest** com metadados das transforma√ß√µes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0339ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos gerados:\n",
      "- INTERIM:   data\\interim\\interim.parquet\n",
      "- PROCESSED: data\\processed\\processed.parquet\n",
      "- META:      artifacts\\metadata\\dataset_meta.json\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üì¶ Exporta√ß√£o de Artefatos (N1 ‚Üí N2)\n",
    "# =============================================================================\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Caminhos a partir da config (com defaults)\n",
    "OUTPUT_PROCESSED = Path(config.get(\"data_processed_file\", \"data/processed/processed.parquet\"))\n",
    "OUTPUT_INTERIM   = Path(config.get(\"data_interim_file\",   \"data/interim/interim.parquet\"))\n",
    "META_FILE        = Path(config.get(\"meta_file\",           \"artifacts/metadata/dataset_meta.json\"))\n",
    "\n",
    "# 2) Garante diret√≥rios\n",
    "OUTPUT_PROCESSED.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_INTERIM.parent.mkdir(parents=True, exist_ok=True)\n",
    "META_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)  # deve existir na sua c√©lula anterior\n",
    "\n",
    "# 3) Salva tabelas respeitando a extens√£o (.csv / .parquet / .xlsx)\n",
    "def _save_df(df_, path_: Path):\n",
    "    ext = path_.suffix.lower()\n",
    "    if ext == \".parquet\":\n",
    "        df_.to_parquet(path_, index=False)\n",
    "    elif ext == \".csv\":\n",
    "        df_.to_csv(path_, index=False, encoding=\"utf-8\")\n",
    "    elif ext == \".xlsx\":\n",
    "        df_.to_excel(path_, index=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Extens√£o n√£o suportada: {ext}\")\n",
    "\n",
    "if config.get(\"export_interim\", True):\n",
    "    _save_df(df, OUTPUT_INTERIM)\n",
    "\n",
    "if config.get(\"export_processed\", True):\n",
    "    _save_df(df, OUTPUT_PROCESSED)\n",
    "\n",
    "# 4) Monta METADADOS para o N2\n",
    "#    - target: vem da config (ou voc√™ pode setar manualmente)\n",
    "target_col = config.get(\"target_column\", \"target\")\n",
    "\n",
    "# Listas de colunas\n",
    "all_cols = df.columns.tolist()\n",
    "ignored_cols = config.get(\"ignored_columns\", [])  # opcional na sua config\n",
    "candidate_features = [c for c in all_cols if c not in ignored_cols and c != target_col]\n",
    "\n",
    "numeric_cols = df[candidate_features].select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in candidate_features if c not in numeric_cols]\n",
    "boolean_cols = df[candidate_features].select_dtypes(include=[\"bool\", \"boolean\"]).columns.tolist()\n",
    "\n",
    "# (Se quiser registrar o mapeamento de classes do target, defina aqui; opcional)\n",
    "class_map = None\n",
    "# Exemplo (apenas se fizer sentido no seu dataset):\n",
    "# classes = sorted(df[target_col].dropna().unique().tolist())\n",
    "# class_map = {c: i for i, c in enumerate(classes)}\n",
    "# df[target_col] = df[target_col].map(class_map)\n",
    "\n",
    "meta = {\n",
    "    \"dataset_name\": config.get(\"dataset_name\", \"Dataset\"),\n",
    "    \"version\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"target\": target_col,\n",
    "    \"class_map\": class_map,\n",
    "    \"columns\": {\n",
    "        \"numeric\": numeric_cols,\n",
    "        \"categorical\": categorical_cols,\n",
    "        \"boolean\": boolean_cols,\n",
    "        \"ignored\": ignored_cols,\n",
    "        \"all\": all_cols\n",
    "    }\n",
    "}\n",
    "\n",
    "# 5) Salva META\n",
    "META_FILE.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "# 6) Manifest opcional (resumo da execu√ß√£o do N1)\n",
    "manifest = {\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"config\": config,\n",
    "    \"memory_mb\": float(df.memory_usage(deep=True).sum() / (1024**2)),\n",
    "    \"outlier_flags\": [c for c in df.columns if c.endswith(\"_is_outlier\")],\n",
    "    \"imputed_flags\": [c for c in df.columns if c.startswith(\"was_imputed_\")],\n",
    "    \"shape\": tuple(df.shape),\n",
    "    \"exported\": {\n",
    "        \"interim\": str(OUTPUT_INTERIM) if config.get(\"export_interim\", True) else None,\n",
    "        \"processed\": str(OUTPUT_PROCESSED) if config.get(\"export_processed\", True) else None,\n",
    "        \"meta_file\": str(META_FILE)\n",
    "    }\n",
    "}\n",
    "(ARTIFACTS_DIR / \"manifest.json\").write_text(json.dumps(manifest, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Arquivos gerados:\")\n",
    "print(f\"- INTERIM:   {OUTPUT_INTERIM if config.get('export_interim', True) else '(pulado)'}\")\n",
    "print(f\"- PROCESSED: {OUTPUT_PROCESSED if config.get('export_processed', True) else '(pulado)'}\")\n",
    "print(f\"- META:      {META_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60f7c2",
   "metadata": {},
   "source": [
    "## ‚úÖ Checkpoint\n",
    "\n",
    "- **Revisar** as colunas derivadas e decis√µes (imputa√ß√£o, outliers, codifica√ß√£o).  \n",
    "- **Documentar** no README as escolhas de neg√≥cio e justificativas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da717ec1",
   "metadata": {},
   "source": [
    "## üìé Anota√ß√µes\n",
    "\n",
    "Esta se√ß√£o pode ser usada como bloco livre para observa√ß√µes espec√≠ficas do projeto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda159f-e8c4-4425-a54d-1e4c3e1c186b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
