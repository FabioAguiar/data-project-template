{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4129a199",
   "metadata": {},
   "source": [
    "# N2 ‚Äî Model Training Control Panel (Template)\n",
    "\n",
    "> **Objetivo:** Este notebook implementa um **painel de controle** para sele√ß√£o de modelos, ajuste de hiperpar√¢metros, treinamento, avalia√ß√£o e exporta√ß√£o dos artefatos `.joblib`.\n",
    "\n",
    "**Como funciona**\n",
    "1. Selecione os modelos nos *checkboxes*.\n",
    "2. As **abas** (tabs) aparecem com formul√°rios espec√≠ficos por modelo.\n",
    "3. Clique no bot√£o **Don't Panic** para treinar e avaliar.\n",
    "4. (Opcional) Marque quais modelos exportar e confirme a exporta√ß√£o.\n",
    "\n",
    "> C√≥digo em ingl√™s; narrativa e coment√°rios em portugu√™s ‚Äî para manter clareza e consist√™ncia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd996fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "/* Deixa as abas e cart√µes mais agrad√°veis */\n",
       ".widget-tab > .p-TabBar .p-TabBar-tabLabel { font-weight: 600; }\n",
       ".card { border-radius: 16px; padding: 16px; box-shadow: 0 6px 24px rgba(0,0,0,.15); margin-bottom: 12px; }\n",
       ".hrow { display:flex; gap:12px; flex-wrap:wrap; align-items:center; }\n",
       ".label { font-weight:600; opacity:.9; }\n",
       "hr { opacity:.25; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports principais\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gr√°ficos\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Pr√©-processamento e modelagem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# LightGBM √© opcional\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    HAS_LGBM = True\n",
    "except Exception:\n",
    "    HAS_LGBM = False\n",
    "\n",
    "# Widgets (UI)\n",
    "import ipywidgets as W\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Persist√™ncia\n",
    "import joblib\n",
    "\n",
    "# Estilos r√°pidos para a UI\n",
    "HTML(\"\"\"<style>\n",
    "/* Deixa as abas e cart√µes mais agrad√°veis */\n",
    ".widget-tab > .p-TabBar .p-TabBar-tabLabel { font-weight: 600; }\n",
    ".card { border-radius: 16px; padding: 16px; box-shadow: 0 6px 24px rgba(0,0,0,.15); margin-bottom: 12px; }\n",
    ".hrow { display:flex; gap:12px; flex-wrap:wrap; align-items:center; }\n",
    ".label { font-weight:600; opacity:.9; }\n",
    "hr { opacity:.25; }\n",
    "</style>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f9a64",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configura√ß√£o e caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03737d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active config:\n",
      "{}\n",
      "\n",
      "Paths:\n",
      " RAW: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\notebooks\\data\\raw\n",
      " PROCESSED: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\notebooks\\data\\processed\n",
      " ARTIFACTS: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\notebooks\\artifacts\n",
      " MODELS: C:\\Users\\fabio\\Projetos DEV\\data projects\\data-project-template\\notebooks\\artifacts\\models\n"
     ]
    }
   ],
   "source": [
    "# Carregar config se existir\n",
    "CONFIG_DIR = Path(\"config\")\n",
    "DEFAULTS = CONFIG_DIR / \"defaults.json\"\n",
    "LOCAL = CONFIG_DIR / \"local.json\"\n",
    "\n",
    "config = {}\n",
    "if DEFAULTS.exists():\n",
    "    config.update(json.loads(DEFAULTS.read_text(encoding=\"utf-8\")))\n",
    "if LOCAL.exists():\n",
    "    # sobrep√µe defaults com local\n",
    "    config.update(json.loads(LOCAL.read_text(encoding=\"utf-8\")))\n",
    "\n",
    "print(\"Active config:\")\n",
    "print(json.dumps(config, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Caminhos padr√£o\n",
    "DATA_RAW = Path(config.get(\"data_raw\", \"data/raw\"))\n",
    "DATA_PROCESSED = Path(config.get(\"data_processed\", \"data/processed\"))\n",
    "ARTIFACTS = Path(config.get(\"artifacts_dir\", \"artifacts\"))\n",
    "ART_MODELS = ARTIFACTS / \"models\"\n",
    "ART_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = int(config.get(\"random_state\", 42))\n",
    "TEST_SIZE = float(config.get(\"test_size\", 0.2))\n",
    "TARGET_COL = config.get(\"target_column\", \"target\")  # ajuste conforme seu dataset\n",
    "\n",
    "print(\"\\nPaths:\")\n",
    "print(\" RAW:\", DATA_RAW.resolve())\n",
    "print(\" PROCESSED:\", DATA_PROCESSED.resolve())\n",
    "print(\" ARTIFACTS:\", ARTIFACTS.resolve())\n",
    "print(\" MODELS:\", ART_MODELS.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83334d0",
   "metadata": {},
   "source": [
    "## üì¶ Carregamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9461b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data\\processed\\processed.parquet ‚Äî shape: (7043, 148)\n",
      "[info] meta carregado de artifacts\\metadata\\dataset_meta.json\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Target column 'target' n√£o encontrada no dataset.\\n‚Üí Defina 'target_column' em config/defaults.json ou ajuste 'meta_file'.\\nColunas dispon√≠veis: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity']...\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m TARGET_COL \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChurn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TARGET_COL \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTARGET_COL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m n√£o encontrada no dataset.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚Üí Defina \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_column\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m em config/defaults.json ou ajuste \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_file\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColunas dispon√≠veis: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)[:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m     )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Map de classes (se vier do meta)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m class_map \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_map\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Target column 'target' n√£o encontrada no dataset.\\n‚Üí Defina 'target_column' em config/defaults.json ou ajuste 'meta_file'.\\nColunas dispon√≠veis: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity']...\""
     ]
    }
   ],
   "source": [
    "# TODO: adapte para seu caso.\n",
    "# Estrat√©gias:\n",
    "# 1) Ler um CSV j√° 'processado' (num√©rico) e separar features/target;\n",
    "# 2) Ou montar um ColumnTransformer para lidar com num√©ricos/categ√≥ricos antes do treino.\n",
    "\n",
    "from pathlib import Path\n",
    "import json, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _find_processed_candidate():\n",
    "    proc_dir = Path(config.get(\"data_processed_dir\", \"data/processed\"))\n",
    "    candidates = []\n",
    "    if proc_dir.exists():\n",
    "        candidates += sorted(proc_dir.glob(\"*.parquet\"))\n",
    "        candidates += sorted(proc_dir.glob(\"*.csv\"))\n",
    "        candidates += sorted(proc_dir.glob(\"*.xlsx\"))\n",
    "    return proc_dir, candidates\n",
    "\n",
    "# Caminhos vindos da config\n",
    "DATA_PROCESSED = Path(config.get(\"data_processed_file\", \"data/processed/processed.parquet\"))\n",
    "META_FILE = Path(config.get(\"meta_file\", \"artifacts/metadata/dataset_meta.json\"))\n",
    "\n",
    "# Se o arquivo configurado n√£o existir, tenta auto-descobrir\n",
    "if not DATA_PROCESSED.exists():\n",
    "    proc_dir, cands = _find_processed_candidate()\n",
    "    if cands:\n",
    "        # Estrat√©gia: prioriza parquet, depois csv, depois xlsx\n",
    "        DATA_PROCESSED = cands[0]\n",
    "        print(f\"[info] data_processed_file n√£o encontrado. Usando candidato: {DATA_PROCESSED}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            \"Nenhum dataset processado encontrado.\\n\"\n",
    "            f\"Tente uma destas op√ß√µes:\\n\"\n",
    "            f\"  1) Salvar seu dataset em {Path('data/processed/processed.parquet').as_posix()} ou\\n\"\n",
    "            f\"  2) Definir 'data_processed_file' em config/defaults.json apontando para o arquivo certo\\n\"\n",
    "            f\"  3) Colocar qualquer .parquet/.csv/.xlsx em data/processed/ para auto-descoberta\"\n",
    "        )\n",
    "\n",
    "# Leitura do dataset\n",
    "suffix = DATA_PROCESSED.suffix.lower()\n",
    "if suffix == \".parquet\":\n",
    "    try:\n",
    "        df = pd.read_parquet(DATA_PROCESSED)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] Falha ao ler parquet. Voc√™ tem 'pyarrow' instalado? Tentando instru√ß√£o:\")\n",
    "        print(\"      pip install pyarrow\")\n",
    "        raise\n",
    "elif suffix == \".csv\":\n",
    "    df = pd.read_csv(DATA_PROCESSED)\n",
    "elif suffix == \".xlsx\":\n",
    "    df = pd.read_excel(DATA_PROCESSED)\n",
    "else:\n",
    "    raise ValueError(f\"Extens√£o n√£o suportada: {suffix}\")\n",
    "\n",
    "print(f\"Loaded: {DATA_PROCESSED} ‚Äî shape: {df.shape}\")\n",
    "\n",
    "# Metadados (opcional)\n",
    "meta = {}\n",
    "if META_FILE.exists():\n",
    "    try:\n",
    "        meta = json.loads(META_FILE.read_text(encoding=\"utf-8\"))\n",
    "        print(f\"[info] meta carregado de {META_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] falha lendo meta '{META_FILE}': {e}\")\n",
    "\n",
    "TARGET_COL = meta.get(\"target\", config.get(\"Churn\", \"target\"))\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise KeyError(\n",
    "        f\"Target column '{TARGET_COL}' n√£o encontrada no dataset.\\n\"\n",
    "        \"‚Üí Defina 'target_column' em config/defaults.json ou ajuste 'meta_file'.\\n\"\n",
    "        f\"Colunas dispon√≠veis: {list(df.columns)[:10]}...\"\n",
    "    )\n",
    "\n",
    "# Map de classes (se vier do meta)\n",
    "class_map = meta.get(\"class_map\")\n",
    "if class_map:\n",
    "    df[TARGET_COL] = df[TARGET_COL].map(class_map)\n",
    "\n",
    "# Defini√ß√£o de colunas (prioriza meta)\n",
    "cols_meta = meta.get(\"columns\", {})\n",
    "ignored_cols = set(cols_meta.get(\"ignored\", []))\n",
    "candidate_features = [c for c in df.columns if c not in ignored_cols and c != TARGET_COL]\n",
    "\n",
    "# Infer√™ncia caso meta n√£o traga listas\n",
    "numeric_cols = cols_meta.get(\"numeric\") or df[candidate_features].select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = cols_meta.get(\"categorical\") or [c for c in candidate_features if c not in numeric_cols]\n",
    "\n",
    "# Booleans (opcional no meta)\n",
    "bool_cols = cols_meta.get(\"boolean\", [])\n",
    "for c in bool_cols:\n",
    "    if c in candidate_features and c not in categorical_cols and c not in numeric_cols:\n",
    "        categorical_cols.append(c)\n",
    "\n",
    "feature_cols = numeric_cols + categorical_cols\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET_COL].copy()\n",
    "\n",
    "print(\"numeric_cols:\", numeric_cols[:8], \"...\" if len(numeric_cols) > 8 else \"\")\n",
    "print(\"categorical_cols:\", categorical_cols[:8], \"...\" if len(categorical_cols) > 8 else \"\")\n",
    "print(\"ignored_cols:\", list(ignored_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6e108",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Split e Pr√©‚Äëprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebf5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Pr√©-processamento padr√£o (imputa√ß√£o + escala para num√©ricos; imputa√ß√£o + one-hot para categ√≥ricos)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=True))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc117e0",
   "metadata": {},
   "source": [
    "## üß∞ Seletor de Modelos e Formul√°rios (UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dac3075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b00027173ca454ba0a2ce721b92eece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Model selection</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6776f6306ccf4bce8e97f1eb9037a869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<div class='card'>Selecione os modelos abaixo:</div>\"), HBox(children=(Checkbox(val‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab90698ae9a04de68919c24c4fc1b5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Hyperparameters</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4558cbc84498476aa58c40cfa787313e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HBox(children=(HTML(value=\"<div class='label' style='min-width:160px'>n_estimator‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defini√ß√£o dos modelos suportados\n",
    "MODEL_SPECS = {\n",
    "    \"Dummy\": {\n",
    "        \"class\": DummyClassifier,\n",
    "        \"params\": {\n",
    "            \"strategy\": W.Dropdown(options=[\"most_frequent\", \"prior\", \"stratified\", \"uniform\"], value=\"most_frequent\"),\n",
    "            \"random_state\": W.IntText(value=RANDOM_STATE)\n",
    "        }\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"class\": KNeighborsClassifier,\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": W.IntSlider(value=5, min=1, max=50, step=1),\n",
    "            \"weights\": W.Dropdown(options=[\"uniform\", \"distance\"], value=\"uniform\"),\n",
    "            \"p\": W.Dropdown(options=[1, 2], value=2)\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"class\": RandomForestClassifier,\n",
    "        \"params\": {\n",
    "            \"n_estimators\": W.IntSlider(value=200, min=50, max=1000, step=50),\n",
    "            \"max_depth\": W.IntSlider(value=None, min=1, max=50, step=1),\n",
    "            \"min_samples_split\": W.IntSlider(value=2, min=2, max=20, step=1),\n",
    "            \"min_samples_leaf\": W.IntSlider(value=1, min=1, max=20, step=1),\n",
    "            \"bootstrap\": W.Checkbox(value=True),\n",
    "            \"random_state\": W.IntText(value=RANDOM_STATE),\n",
    "            \"n_jobs\": W.IntText(value=-1)\n",
    "        }\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"class\": LogisticRegression,\n",
    "        \"params\": {\n",
    "            \"C\": W.FloatLogSlider(value=1.0, base=10, min=-2, max=2, step=0.1),\n",
    "            \"penalty\": W.Dropdown(options=[\"l2\", \"l1\", \"elasticnet\", \"none\"], value=\"l2\"),\n",
    "            \"solver\": W.Dropdown(options=[\"lbfgs\", \"liblinear\", \"saga\", \"newton-cg\"], value=\"lbfgs\"),\n",
    "            \"max_iter\": W.IntSlider(value=1000, min=100, max=5000, step=100),\n",
    "            \"n_jobs\": W.IntText(value=None)\n",
    "        }\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"class\": DecisionTreeClassifier,\n",
    "        \"params\": {\n",
    "            \"criterion\": W.Dropdown(options=[\"gini\", \"entropy\", \"log_loss\"], value=\"gini\"),\n",
    "            \"max_depth\": W.IntSlider(value=None, min=1, max=50, step=1),\n",
    "            \"min_samples_split\": W.IntSlider(value=2, min=2, max=20, step=1),\n",
    "            \"min_samples_leaf\": W.IntSlider(value=1, min=1, max=20, step=1)\n",
    "        }\n",
    "    },\n",
    "    \"NaiveBayes\": {\n",
    "        \"class\": GaussianNB,\n",
    "        \"params\": {\n",
    "            # GaussianNB tem poucos hiperpar√¢metros\n",
    "            \"var_smoothing\": W.FloatLogSlider(value=1e-9, base=10, min=-12, max=-3, step=0.1)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if HAS_LGBM:\n",
    "    MODEL_SPECS[\"LightGBM\"] = {\n",
    "        \"class\": LGBMClassifier,\n",
    "        \"params\": {\n",
    "            \"n_estimators\": W.IntSlider(value=400, min=50, max=2000, step=50),\n",
    "            \"learning_rate\": W.FloatLogSlider(value=0.05, base=10, min=-3, max=0, step=0.05),\n",
    "            \"num_leaves\": W.IntSlider(value=31, min=8, max=512, step=1),\n",
    "            \"max_depth\": W.IntSlider(value=-1, min=-1, max=64, step=1),\n",
    "            \"subsample\": W.FloatSlider(value=1.0, min=0.5, max=1.0, step=0.05),\n",
    "            \"colsample_bytree\": W.FloatSlider(value=1.0, min=0.5, max=1.0, step=0.05),\n",
    "            \"random_state\": W.IntText(value=RANDOM_STATE),\n",
    "            \"n_jobs\": W.IntText(value=-1)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Checkbox por modelo\n",
    "checkboxes = {name: W.Checkbox(description=name, value=(name in [\"RandomForest\", \"LogisticRegression\"])) \n",
    "              for name in MODEL_SPECS.keys()}\n",
    "\n",
    "checkbox_row = W.HBox(list(checkboxes.values()))\n",
    "\n",
    "# Abas din√¢micas com formul√°rios\n",
    "tab = W.Tab()\n",
    "forms = {}\n",
    "titles = []\n",
    "\n",
    "def build_form_for(model_name):\n",
    "    # monta um formul√°rio (VBox) com widgets dos hiperpar√¢metros\n",
    "    spec = MODEL_SPECS[model_name]\n",
    "    widgets = []\n",
    "    for p_name, widget in spec[\"params\"].items():\n",
    "        widgets.append(W.HBox([W.HTML(f\"<div class='label' style='min-width:160px'>{p_name}</div>\"), widget]))\n",
    "    form = W.VBox(widgets, layout=W.Layout(border=\"1px solid #ddd\", padding=\"10px\", border_radius=\"12px\"))\n",
    "    return form\n",
    "\n",
    "def refresh_tabs(*args):\n",
    "    global titles, forms\n",
    "    chosen = [name for name, cb in checkboxes.items() if cb.value]\n",
    "    titles = chosen\n",
    "    children = []\n",
    "    forms = {}\n",
    "    for name in chosen:\n",
    "        forms[name] = build_form_for(name)\n",
    "        children.append(forms[name])\n",
    "    if not children:\n",
    "        tab.children = ()\n",
    "    else:\n",
    "        tab.children = tuple(children)\n",
    "        for i, title in enumerate(titles):\n",
    "            tab.set_title(i, title)\n",
    "\n",
    "for cb in checkboxes.values():\n",
    "    cb.observe(refresh_tabs, names=\"value\")\n",
    "\n",
    "refresh_tabs()  # inicializa com sele√ß√£o padr√£o\n",
    "\n",
    "display(W.HTML(\"<h3>Model selection</h3>\"))\n",
    "display(W.VBox([W.HTML(\"<div class='card'>Selecione os modelos abaixo:</div>\"), checkbox_row]))\n",
    "display(W.HTML(\"<h3>Hyperparameters</h3>\"))\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0593c",
   "metadata": {},
   "source": [
    "## üöÄ Treino, Avalia√ß√£o e Exporta√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f690d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088548e8eb014ac1b47dd5532c40e0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='danger', description=\"Don't Panic\", icon='rocket', style=ButtonStyle()),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a5e26f95ab4a8796fef83e68c79852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ca8b935fa2424d93fc131ddedb3330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<hr/>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee77db9915e475cbc6495d026be65d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6191487533c548aaa0e6758b522240c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Export selected', icon='save', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b183126cd304c7e826fd1ebcac981ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bot√£o de execu√ß√£o\n",
    "run_btn = W.Button(description=\"Don't Panic\", button_style='danger', icon=\"rocket\")\n",
    "export_label = W.HTML(\"<b>Export selected models after training?</b>\")\n",
    "export_checkboxes = {}\n",
    "export_box = W.VBox()\n",
    "\n",
    "output = W.Output()\n",
    "\n",
    "def build_model_instance(name):\n",
    "    spec = MODEL_SPECS[name]\n",
    "    cls = spec[\"class\"]\n",
    "    # ler valores atuais dos widgets do formul√°rio\n",
    "    params = {}\n",
    "    for p_name, widget in spec[\"params\"].items():\n",
    "        try:\n",
    "            params[p_name] = widget.value\n",
    "        except Exception:\n",
    "            pass\n",
    "    # ajustar casos especiais (None convertido indevidamente)\n",
    "    for k, v in list(params.items()):\n",
    "        if isinstance(v, str) and v.lower() == \"none\":\n",
    "            params[k] = None\n",
    "    model = cls(**params)\n",
    "    pipe = Pipeline([\n",
    "        (\"pre\", preprocessor),\n",
    "        (\"clf\", model)\n",
    "    ])\n",
    "    return pipe, params\n",
    "\n",
    "def plot_confusion(ax, y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    im = ax.imshow(cm)\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        ax.text(j, i, int(val), ha=\"center\", va=\"center\")\n",
    "    return im\n",
    "\n",
    "def plot_roc(ax, y_true, y_proba):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    auc_val = roc_auc_score(y_true, y_proba)\n",
    "    ax.plot(fpr, tpr, label=f\"ROC AUC = {auc_val:.3f}\")\n",
    "    ax.plot([0,1],[0,1], linestyle='--')\n",
    "    ax.set_title(\"ROC Curve\")\n",
    "    ax.set_xlabel(\"FPR\")\n",
    "    ax.set_ylabel(\"TPR\")\n",
    "    ax.legend()\n",
    "\n",
    "def on_click_run(_):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        chosen = [name for name, cb in checkboxes.items() if cb.value]\n",
    "        if not chosen:\n",
    "            print(\"Nenhum modelo selecionado.\")\n",
    "            return\n",
    "\n",
    "        results = {}\n",
    "        for name in chosen:\n",
    "            print(f\"\\n=== Training: {name} ===\")\n",
    "            pipe, params = build_model_instance(name)\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_pred = pipe.predict(X_test)\n",
    "            metrics = {\n",
    "                \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "                \"f1\": f1_score(y_test, y_pred, average=\"binary\") if len(np.unique(y_test)) == 2 else f1_score(y_test, y_pred, average=\"macro\")\n",
    "            }\n",
    "\n",
    "            print(\"Params:\", params)\n",
    "            print(\"Accuracy:\", f\"{metrics['accuracy']:.4f}\")\n",
    "            print(\"F1:\", f\"{metrics['f1']:.4f}\")\n",
    "\n",
    "            # Plots\n",
    "            fig1 = plt.figure()\n",
    "            ax1 = fig1.add_subplot(111)\n",
    "            plot_confusion(ax1, y_test, y_pred)\n",
    "            plt.show()\n",
    "\n",
    "            # ROC se proba dispon√≠vel e problema bin√°rio\n",
    "            proba_available = hasattr(pipe.named_steps[\"clf\"], \"predict_proba\")\n",
    "            if proba_available and len(np.unique(y_test)) == 2:\n",
    "                y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "                fig2 = plt.figure()\n",
    "                ax2 = fig2.add_subplot(111)\n",
    "                plot_roc(ax2, y_test, y_proba)\n",
    "                plt.show()\n",
    "\n",
    "            results[name] = {\"pipeline\": pipe, \"metrics\": metrics}\n",
    "\n",
    "        # Montar checkboxes de exporta√ß√£o\n",
    "        export_options = []\n",
    "        export_checkboxes.clear()\n",
    "        for name in results.keys():\n",
    "            cb = W.Checkbox(description=f\"Export {name}.joblib\", value=True)\n",
    "            export_checkboxes[name] = cb\n",
    "            export_options.append(cb)\n",
    "        export_box.children = tuple([export_label] + export_options)\n",
    "\n",
    "        # Guardar resultados na inst√¢ncia do bot√£o (simples)\n",
    "        run_btn.results = results\n",
    "\n",
    "run_btn.on_click(on_click_run)\n",
    "\n",
    "display(W.HBox([run_btn]))\n",
    "display(output)\n",
    "display(W.HTML(\"<hr/>\"))\n",
    "display(export_box)\n",
    "\n",
    "# Bot√£o para confirmar exporta√ß√£o\n",
    "confirm_export_btn = W.Button(description=\"Export selected\", button_style='success', icon=\"save\")\n",
    "export_status = W.Output()\n",
    "\n",
    "def on_click_export(_):\n",
    "    export_status.clear_output()\n",
    "    with export_status:\n",
    "        if not hasattr(run_btn, \"results\"):\n",
    "            print(\"Nenhum resultado de treino dispon√≠vel. Execute o treino primeiro.\")\n",
    "            return\n",
    "        results = run_btn.results\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        for name, cb in export_checkboxes.items():\n",
    "            if cb.value:\n",
    "                model_path = ART_MODELS / f\"{name}_{ts}.joblib\"\n",
    "                joblib.dump(results[name][\"pipeline\"], model_path)\n",
    "                print(f\"Saved: {model_path}\")\n",
    "\n",
    "confirm_export_btn.on_click(on_click_export)\n",
    "display(confirm_export_btn)\n",
    "display(export_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee9f57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Notas e Dicas\n",
    "\n",
    "- **Pr√©‚Äëprocessamento:** Ajuste o `ColumnTransformer` conforme seu dataset (dtypes no N1 ajudam muito).\n",
    "- **Curvas ROC:** S√≥ s√£o exibidas quando `predict_proba` existe e o target √© bin√°rio.\n",
    "- **LightGBM:** Habilitado automaticamente se estiver instalado no ambiente.\n",
    "- **Exporta√ß√£o:** Artefatos salvos em `artifacts/models/ModelName_YYYYMMDD_HHMMSS.joblib`.\n",
    "- **Extensibilidade:** Para adicionar modelos, inclua uma entrada em `MODEL_SPECS` com `class` e `params`.\n",
    "\n",
    "> Qualquer etapa visual pode ser personalizada com HTML + CSS dentro do notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
